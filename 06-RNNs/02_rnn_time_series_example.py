# -*- coding: utf-8 -*-
"""02-RNN-Time-Series-Example.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1l7eASfW7YP7ANjN5ytd65EbYIjpaMPyX

# RNN Example for Time Series
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

"""## Data

Release: Advance Monthly Sales for Retail and Food Services  
Units:  Millions of Dollars, Not Seasonally Adjusted

Frequency:  Monthly

The value for the most recent month is an advance estimate that is based on data from a subsample of firms from the larger Monthly Retail Trade Survey. The advance estimate will be superseded in following months by revised estimates derived from the larger Monthly Retail Trade Survey. The associated series from the Monthly Retail Trade Survey is available at https://fred.stlouisfed.org/series/MRTSSM448USN

Information about the Advance Monthly Retail Sales Survey can be found on the Census website at https://www.census.gov/retail/marts/about_the_surveys.html

Suggested Citation:
U.S. Census Bureau, Advance Retail Sales: Clothing and Clothing Accessory Stores [RSCCASN], retrieved from FRED, Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/RSCCASN, November 16, 2019.

https://fred.stlouisfed.org/series/RSCCASN
"""

df = pd.read_csv('RSCCASN.csv',index_col='DATE',parse_dates=True)

df.info()

df.head()

df.columns = ['Sales']

df.plot(figsize=(12,8))
plt.show()

"""## Train Test Split"""

len(df)

"""Data is monthly, let's forecast 1.5 years into the future."""

test_size = 18

test_ind = len(df)- test_size

train = df.iloc[:test_ind]
test = df.iloc[test_ind:]

train

test

"""## Scale Data"""

from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler()

scaler.fit(train)

scaled_train = scaler.transform(train)
scaled_test = scaler.transform(test)

scaled_train.max()

"""# Time Series Generator

This class takes in a sequence of data-points gathered at
equal intervals, along with time series parameters such as
stride, length of history, etc., to produce batches for
training/validation.

#### Arguments
    data: Indexable generator (such as list or Numpy array)
        containing consecutive data points (timesteps).
        The data should be at 2D, and axis 0 is expected
        to be the time dimension.
    targets: Targets corresponding to timesteps in `data`.
        It should have same length as `data`.
    length: Length of the output sequences (in number of timesteps).
    sampling_rate: Period between successive individual timesteps
        within sequences. For rate `r`, timesteps
        `data[i]`, `data[i-r]`, ... `data[i - length]`
        are used for create a sample sequence.
    stride: Period between successive output sequences.
        For stride `s`, consecutive output samples would
        be centered around `data[i]`, `data[i+s]`, `data[i+2*s]`, etc.
    start_index: Data points earlier than `start_index` will not be used
        in the output sequences. This is useful to reserve part of the
        data for test or validation.
    end_index: Data points later than `end_index` will not be used
        in the output sequences. This is useful to reserve part of the
        data for test or validation.
    shuffle: Whether to shuffle output samples,
        or instead draw them in chronological order.
    reverse: Boolean: if `true`, timesteps in each output sample will be
        in reverse chronological order.
    batch_size: Number of timeseries samples in each batch
        (except maybe the last one).
"""

from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator

# Let's redefine to get 12 months back and then predict the next month out
length = 12
generator = TimeseriesGenerator(scaled_train, scaled_train, length=length, batch_size=1)

# What does the first batch look like?
X,y = generator[0]

print(f'Given the Array: \n{X.flatten()}')
print(f'Predict this y: \n {y}')

"""### Create the Model"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM

# We're only using one feature in our time series
n_features = 1

# define model
model = Sequential()

# LSTM layer
model.add(LSTM(100, activation='relu', input_shape=(length, n_features)))

# Final Prediction
model.add(Dense(1))

model.compile(optimizer='adam', loss='mse')

model.summary()

"""### EarlyStopping and creating a Validation Generator

NOTE: The scaled_test dataset size MUST be greater than your length chosen for your batches. Review video for more info on this.
"""

from tensorflow.keras.callbacks import EarlyStopping

# patience = 2, cause there is too much noise
early_stop = EarlyStopping(monitor='val_loss',patience=2)

validation_generator = TimeseriesGenerator(scaled_test,scaled_test, length=length, batch_size=1)

# fit model
model.fit_generator(generator,epochs=20,
                    validation_data=validation_generator,
                   callbacks=[early_stop])

losses = pd.DataFrame(model.history.history)

losses.plot()
plt.show()

"""## Evaluate on Test Data"""

first_eval_batch = scaled_train[-length:]

first_eval_batch

# prediction list
test_predictions = []

first_eval_batch = scaled_train[-length:]

# update variable
current_batch = first_eval_batch.reshape((1, length, n_features))

for i in range(len(test)):
    
    # get prediction 1 time stamp ahead ([0] is for grabbing just the number instead of [array])
    current_pred = model.predict(current_batch)[0]
    
    # store prediction
    test_predictions.append(current_pred) 
    
    # update batch to now include prediction and drop first value
    current_batch = np.append(current_batch[:,1:,:],[[current_pred]],axis=1)

"""## Inverse Transformations and Compare"""

true_predictions = scaler.inverse_transform(test_predictions)

# IGNORE WARNINGS
test['Predictions'] = true_predictions

test.head()

test.plot(figsize=(12,8))
plt.show()

"""# Retrain and Forecasting"""

full_scaler = MinMaxScaler()
scaled_full_data = full_scaler.fit_transform(df)

length = 12 # Length of the output sequences (in number of timesteps)
generator = TimeseriesGenerator(scaled_full_data, scaled_full_data, length=length, batch_size=1)

# new forecaste model
model = Sequential()
model.add(LSTM(100, activation='relu', input_shape=(length, n_features)))
model.add(Dense(1))
model.compile(optimizer='adam', loss='mse')

model.summary()

# fit model
model.fit_generator(generator,epochs=5)

forecast = []
# Replace periods with whatever forecast length you want
periods = 12

first_eval_batch = scaled_full_data[-length:]
current_batch = first_eval_batch.reshape((1, length, n_features))

for i in range(periods):
    
    # get prediction 1 time stamp ahead ([0] is for grabbing just the number instead of [array])
    current_pred = model.predict(current_batch)[0]
    
    # store prediction
    forecast.append(current_pred) 
    
    # update batch to now include prediction and drop first value
    current_batch = np.append(current_batch[:,1:,:],[[current_pred]],axis=1)

forecast = scaler.inverse_transform(forecast)

"""### Creating new timestamp index with pandas."""

df.head()

forecast_index = pd.date_range(start='2019-11-01',periods=periods,freq='MS')

forecast_index

forecast_df = pd.DataFrame(data=forecast,index=forecast_index,
                           columns=['Forecast'])

forecast_df

df.plot()
forecast_df.plot()
plt.show()

"""### Joining pandas plots

https://stackoverflow.com/questions/13872533/plot-different-dataframes-in-the-same-figure
"""

ax = df.plot(figsize=(10,7))
forecast_df.plot(ax=ax)
plt.show()

# xlim
ax = df.plot(figsize=(10,7))
forecast_df.plot(ax=ax)
plt.xlim('2018-01-01','2020-12-01')
plt.show()

model.save('retail_sales_model.h5')