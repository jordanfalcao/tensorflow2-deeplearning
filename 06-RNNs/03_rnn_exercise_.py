# -*- coding: utf-8 -*-
"""03-RNN-Exercise .ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16ktmtD0pxG5hbkCpUS58V-gM6nVBNAUp

# RNN Exercise

**TASK: IMPORT THE BASIC LIBRARIES YOU THINK YOU WILL USE**
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

"""## Data

Info about this data set: https://fred.stlouisfed.org/series/IPN31152N


Units:  Index 2012=100, Not Seasonally Adjusted

Frequency:  Monthly

The industrial production (IP) index measures the real output of all relevant establishments located in the United States, regardless of their ownership, but not those located in U.S. territories.

NAICS = 31152

Source Code: IP.N31152.N

Suggested Citation:
Board of Governors of the Federal Reserve System (US), Industrial Production: Nondurable Goods: Ice cream and frozen dessert [IPN31152N], retrieved from FRED, Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/IPN31152N, November 16, 2019.

# Project Tasks

**TASK: Read in the data set "Frozen_Dessert_Production.csv" from the Data folder. Figure out how to set the date to a datetime index columns**
"""

df = pd.read_csv('Frozen_Dessert_Production.csv', index_col='DATE')

df.head()

"""**Task: Change the column name to Production**"""

df.columns = ['Production']

df.head()

"""**TASK: Plot out the time series**"""

df.plot(figsize=(12,8))
plt.show()

"""## Train Test Split

**TASK: Figure out the length of the data set**
"""

len(df)

"""**TASK: Split the data into a train/test split where the test set is the last 24 months of data.**"""

test_size = 24

train = df[:-test_size]
test = df[-test_size:]

len(test)

len(train)

"""## Scale Data

**TASK: Use a MinMaxScaler to scale the train and test sets into scaled versions.**
"""

from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler()

scaler.fit(train)

scaled_train = scaler.transform(train)
scaled_test = scaler.transform(test)

scaled_train.max()

"""# Time Series Generator

**TASK: Create a TimeSeriesGenerator object based off the scaled_train data. The batch length is up to you, but at a minimum it should be at least 18 to capture a full year seasonality.**
"""

from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator

length = 18
n_features = 1
generator = TimeseriesGenerator(scaled_train, scaled_train, length=length, batch_size=1)

"""### Create the Model

**TASK: Create a Keras Sequential Model with as many LSTM units you want and a final Dense Layer.**
"""

from tensorflow.keras.layers import Dense, LSTM
from tensorflow.keras.models import Sequential

# define model
model = Sequential()

model.add(LSTM(units=100, input_shape=(length, 1), activation='relu'))

model.add(Dense(1))

model.compile(loss='mse', optimizer='adam')

model.summary()

"""**TASK: Create a generator for the scaled test/validation set. NOTE: Double check that your batch length makes sense for the size of the test set as mentioned in the RNN Time Series video.**"""

validation_generator = TimeseriesGenerator(scaled_test, scaled_test, length=length, batch_size=1)

"""**TASK: Create an EarlyStopping callback based on val_loss.**"""

from tensorflow.keras.callbacks import EarlyStopping

early_stop = EarlyStopping(monitor='val_loss', patience=2)

"""**TASK: Fit the model to the generator, let the EarlyStopping dictate the amount of epochs, so feel free to set the parameter high.**"""

model.fit_generator(generator, epochs=20, validation_data=validation_generator, callbacks=[early_stop])

"""**TASK: Plot the history of the loss that occured during training.**"""

loss = pd.DataFrame(model.history.history)
loss.plot()
plt.show()

"""## Evaluate on Test Data

**TASK: Forecast predictions for your test data range (the last 12 months of the entire dataset). Remember to inverse your scaling transformations. Your final result should be a DataFrame with two columns, the true test values and the predictions.**
"""

test_predictions = []

first_eval_batch = scaled_train[-length:]
current_batch = first_eval_batch.reshape((1, length, n_features))

# loop for prediction
for i in range(len(test)):

  # get prediction 1 time stamp ahead ([0] is for grabbing just the number instead of [array])
  current_pred = model.predict(current_batch)[0]

  # store prediction
  test_predictions.append(current_pred)

  # update batch to now include prediction and drop first value
  current_batch = np.append(current_batch[:,1:,:], [[current_pred]], axis=1)

true_predictions = scaler.inverse_transform(test_predictions)

test['Predictions'] = true_predictions

test

"""**TASK: Plot your predictions versus the True test values. (Your plot may look different than ours).**"""

test.plot(figsize=(8,5))
plt.show()

"""**TASK: Calculate your RMSE.**"""

from sklearn.metrics import mean_squared_error

np.sqrt(mean_squared_error(test['Production'], test['Predictions']))

# model.save('first_frozen_dessert_production_model.h5')

"""## Trying improving these results"""

test_size = 18

train = df[:-test_size]
test = df[-test_size:]

scaler = MinMaxScaler()

scaled_train = scaler.fit_transform(train)
scaled_test = scaler.transform(test)

length = 12
n_features = 1
generator = TimeseriesGenerator(scaled_train, scaled_train, length=length, batch_size=1)

# define model
model = Sequential()
model.add(LSTM(115, activation='relu', input_shape=(length, n_features)))
model.add(Dense(1))
model.compile(optimizer='adam', loss='mse')

model.summary()

validation_generator = TimeseriesGenerator(scaled_test,scaled_test, length=length, batch_size=1)

early_stop = EarlyStopping(monitor='val_loss',patience=3)

model.fit_generator(generator,epochs=20,
                    validation_data=validation_generator,
                   callbacks=[early_stop])

loss = pd.DataFrame(model.history.history)
loss.plot()

test_predictions = []

first_eval_batch = scaled_train[-length:]
current_batch = first_eval_batch.reshape((1, length, n_features))

for i in range(len(test)):
    
    # get prediction 1 time stamp ahead ([0] is for grabbing just the number instead of [array])
    current_pred = model.predict(current_batch)[0]
    
    # store prediction
    test_predictions.append(current_pred) 
    
    # update batch to now include prediction and drop first value
    current_batch = np.append(current_batch[:,1:,:],[[current_pred]],axis=1)

true_predictions = scaler.inverse_transform(test_predictions)

test['Predictions'] = true_predictions

test

test.plot(figsize=(8,5))
plt.show()

np.sqrt(mean_squared_error(test['Production'],test['Predictions']))

"""Do not worth, have to do some modifications."""