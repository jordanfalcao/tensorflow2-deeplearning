{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01-My-Basic-Model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYRm4eZSj1jV"
      },
      "source": [
        "# DEPLOYMENT\n",
        "\n",
        "**Welcome to deployment section! In this section of the course, we will go through the entire deployment process, starting as if you had to create a servicable model from scratch, then deploy it for others to use, either through API or a web form.**\n",
        "\n",
        "# Data\n",
        "\n",
        "For this example we use the very common data set: [iris dataset](https://en.wikipedia.org/wiki/Iris_flower_data_set), which is about flowers. \n",
        "\n",
        "From Wikipedia:\n",
        "The Iris flower data set or Fisher's Iris data set is a multivariate data set introduced by the British statistician and biologist Ronald Fisher in his 1936 paper The use of multiple measurements in taxonomic problems as an example of linear discriminant analysis.[1] It is sometimes called Anderson's Iris data set because Edgar Anderson collected the data to quantify the morphologic variation of Iris flowers of three related species.[2] Two of the three species were collected in the Gasp√© Peninsula \"all from the same pasture, and picked on the same day and measured at the same time by the same person with the same apparatus\".[3]\n",
        "\n",
        "The data set consists of 50 samples from each of three species of Iris (Iris setosa, Iris virginica and Iris versicolor). Four features were measured from each sample: the length and the width of the sepals and petals, in centimeters. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxtOozv-jnHH"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdjB4Ah2j6lO"
      },
      "source": [
        "iris = pd.read_csv(\"iris.csv\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "U0buaV_8AKsY",
        "outputId": "e72ea17d-b81a-4689-eb33-9626aaeb49f0"
      },
      "source": [
        "iris.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal_length</th>\n",
              "      <th>sepal_width</th>\n",
              "      <th>petal_length</th>\n",
              "      <th>petal_width</th>\n",
              "      <th>species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sepal_length  sepal_width  petal_length  petal_width species\n",
              "0           5.1          3.5           1.4          0.2  setosa\n",
              "1           4.9          3.0           1.4          0.2  setosa\n",
              "2           4.7          3.2           1.3          0.2  setosa\n",
              "3           4.6          3.1           1.5          0.2  setosa\n",
              "4           5.0          3.6           1.4          0.2  setosa"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pFkpDXOAQ_U"
      },
      "source": [
        "## Data Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RPGnGp5AToH"
      },
      "source": [
        "### Features and Target"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHaLiATpAOZr"
      },
      "source": [
        "X = iris.drop('species',axis=1)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNVmEuNSAX_C"
      },
      "source": [
        "y = iris['species']"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBuz6DvPAYZe",
        "outputId": "12c4b662-59c8-4059-d244-d04bce614766"
      },
      "source": [
        "y.unique()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['setosa', 'versicolor', 'virginica'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YP0JomVIAbP5"
      },
      "source": [
        "# Lots of ways to one hot encode\n",
        "# https://stackoverflow.com/questions/47573293/unable-to-transform-string-column-to-categorical-matrix-using-keras-and-sklearn\n",
        "# https://stackoverflow.com/questions/35107559/one-hot-encoding-of-string-categorical-features"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EdNLawOAs0_"
      },
      "source": [
        "from sklearn.preprocessing import LabelBinarizer"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnnoBQ6oAvYV"
      },
      "source": [
        "encoder = LabelBinarizer()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xmYTDSIAw2n"
      },
      "source": [
        "y = encoder.fit_transform(y)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Ft91C2cAxa0",
        "outputId": "37562119-b1c9-4363-e222-ad27fed79de4"
      },
      "source": [
        "y[45:55]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olAEy4--GZzW"
      },
      "source": [
        "## Train Test Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iR1UeHOnA4MG"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-PznB3rGZCX"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0DT7vF4GiW6"
      },
      "source": [
        "### Scaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iK2MzEmGeki"
      },
      "source": [
        "scaler = MinMaxScaler()"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krlHeJemGkW9",
        "outputId": "90139012-048c-4778-c3b4-88a4c65fecbd"
      },
      "source": [
        "scaler.fit(X_train)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MinMaxScaler(copy=True, feature_range=(0, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVI0aXDkMm22"
      },
      "source": [
        "scaled_X_train = scaler.transform(X_train)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ruEf7FtMogQ"
      },
      "source": [
        "scaled_X_test = scaler.transform(X_test)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heBkV6IRMsGw"
      },
      "source": [
        "## Model\n",
        "\n",
        "\n",
        "### Creating the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBHXAXbnMp-7"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-uteo4hMt7E"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(units=4,activation='relu',input_shape=[4,]))\n",
        "\n",
        "# Last layer for multi-class classification of 3 species\n",
        "model.add(Dense(units=3,activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsHbOhxOPOcM"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XM4t5_zIPOQN"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cObBMkSJPLqu"
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2VNVb2wPRC5"
      },
      "source": [
        "early_stop = EarlyStopping(patience=10)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Txz561HEPYFN",
        "outputId": "8d39b442-c02b-4f8a-e74e-7a49f62f7751"
      },
      "source": [
        "model.fit(x=scaled_X_train, \n",
        "          y=y_train, \n",
        "          epochs=300,\n",
        "          validation_data=(scaled_X_test, y_test), verbose=1 ,callbacks=[early_stop])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "4/4 [==============================] - 1s 75ms/step - loss: 1.1224 - accuracy: 0.0583 - val_loss: 1.1438 - val_accuracy: 0.0333\n",
            "Epoch 2/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.1173 - accuracy: 0.1000 - val_loss: 1.1380 - val_accuracy: 0.1000\n",
            "Epoch 3/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.1123 - accuracy: 0.1250 - val_loss: 1.1330 - val_accuracy: 0.1000\n",
            "Epoch 4/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.1073 - accuracy: 0.1917 - val_loss: 1.1282 - val_accuracy: 0.1333\n",
            "Epoch 5/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.1026 - accuracy: 0.2833 - val_loss: 1.1236 - val_accuracy: 0.1667\n",
            "Epoch 6/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.0982 - accuracy: 0.3083 - val_loss: 1.1191 - val_accuracy: 0.1667\n",
            "Epoch 7/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.0937 - accuracy: 0.3333 - val_loss: 1.1148 - val_accuracy: 0.2333\n",
            "Epoch 8/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.0895 - accuracy: 0.3500 - val_loss: 1.1105 - val_accuracy: 0.2333\n",
            "Epoch 9/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.0855 - accuracy: 0.3500 - val_loss: 1.1062 - val_accuracy: 0.2333\n",
            "Epoch 10/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.0815 - accuracy: 0.3500 - val_loss: 1.1022 - val_accuracy: 0.2333\n",
            "Epoch 11/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.0776 - accuracy: 0.3500 - val_loss: 1.0979 - val_accuracy: 0.2333\n",
            "Epoch 12/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.0738 - accuracy: 0.3500 - val_loss: 1.0932 - val_accuracy: 0.3000\n",
            "Epoch 13/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.0696 - accuracy: 0.3667 - val_loss: 1.0888 - val_accuracy: 0.2667\n",
            "Epoch 14/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 1.0657 - accuracy: 0.3750 - val_loss: 1.0846 - val_accuracy: 0.2667\n",
            "Epoch 15/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.0617 - accuracy: 0.3750 - val_loss: 1.0808 - val_accuracy: 0.2667\n",
            "Epoch 16/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.0579 - accuracy: 0.3750 - val_loss: 1.0770 - val_accuracy: 0.3000\n",
            "Epoch 17/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.0540 - accuracy: 0.3917 - val_loss: 1.0726 - val_accuracy: 0.3000\n",
            "Epoch 18/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.0496 - accuracy: 0.4000 - val_loss: 1.0685 - val_accuracy: 0.3000\n",
            "Epoch 19/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.0456 - accuracy: 0.4000 - val_loss: 1.0645 - val_accuracy: 0.3000\n",
            "Epoch 20/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.0413 - accuracy: 0.4083 - val_loss: 1.0604 - val_accuracy: 0.3000\n",
            "Epoch 21/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.0373 - accuracy: 0.4167 - val_loss: 1.0565 - val_accuracy: 0.3000\n",
            "Epoch 22/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.0330 - accuracy: 0.4167 - val_loss: 1.0527 - val_accuracy: 0.3000\n",
            "Epoch 23/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.0291 - accuracy: 0.4167 - val_loss: 1.0489 - val_accuracy: 0.3000\n",
            "Epoch 24/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.0248 - accuracy: 0.4167 - val_loss: 1.0450 - val_accuracy: 0.3333\n",
            "Epoch 25/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.0206 - accuracy: 0.4167 - val_loss: 1.0409 - val_accuracy: 0.3667\n",
            "Epoch 26/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 1.0167 - accuracy: 0.4250 - val_loss: 1.0365 - val_accuracy: 0.3667\n",
            "Epoch 27/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.0125 - accuracy: 0.4333 - val_loss: 1.0326 - val_accuracy: 0.3667\n",
            "Epoch 28/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.0085 - accuracy: 0.4333 - val_loss: 1.0285 - val_accuracy: 0.3667\n",
            "Epoch 29/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.0045 - accuracy: 0.4333 - val_loss: 1.0246 - val_accuracy: 0.4000\n",
            "Epoch 30/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.0003 - accuracy: 0.4250 - val_loss: 1.0209 - val_accuracy: 0.4000\n",
            "Epoch 31/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.9962 - accuracy: 0.4333 - val_loss: 1.0174 - val_accuracy: 0.4000\n",
            "Epoch 32/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.9922 - accuracy: 0.4417 - val_loss: 1.0143 - val_accuracy: 0.3667\n",
            "Epoch 33/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.9880 - accuracy: 0.4417 - val_loss: 1.0107 - val_accuracy: 0.4000\n",
            "Epoch 34/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.9840 - accuracy: 0.4417 - val_loss: 1.0075 - val_accuracy: 0.4000\n",
            "Epoch 35/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.9799 - accuracy: 0.4417 - val_loss: 1.0038 - val_accuracy: 0.4333\n",
            "Epoch 36/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.9760 - accuracy: 0.4500 - val_loss: 1.0011 - val_accuracy: 0.4000\n",
            "Epoch 37/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.9718 - accuracy: 0.4583 - val_loss: 0.9981 - val_accuracy: 0.4000\n",
            "Epoch 38/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.9677 - accuracy: 0.4583 - val_loss: 0.9947 - val_accuracy: 0.4000\n",
            "Epoch 39/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.9639 - accuracy: 0.4583 - val_loss: 0.9919 - val_accuracy: 0.4000\n",
            "Epoch 40/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.9599 - accuracy: 0.4833 - val_loss: 0.9885 - val_accuracy: 0.4000\n",
            "Epoch 41/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.9563 - accuracy: 0.4917 - val_loss: 0.9852 - val_accuracy: 0.4333\n",
            "Epoch 42/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.9525 - accuracy: 0.5000 - val_loss: 0.9826 - val_accuracy: 0.4000\n",
            "Epoch 43/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.9490 - accuracy: 0.5000 - val_loss: 0.9794 - val_accuracy: 0.4333\n",
            "Epoch 44/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.9454 - accuracy: 0.5167 - val_loss: 0.9767 - val_accuracy: 0.4667\n",
            "Epoch 45/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.9419 - accuracy: 0.5333 - val_loss: 0.9739 - val_accuracy: 0.4000\n",
            "Epoch 46/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.9384 - accuracy: 0.5333 - val_loss: 0.9710 - val_accuracy: 0.4000\n",
            "Epoch 47/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.9350 - accuracy: 0.5750 - val_loss: 0.9682 - val_accuracy: 0.4000\n",
            "Epoch 48/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.9315 - accuracy: 0.5750 - val_loss: 0.9653 - val_accuracy: 0.4000\n",
            "Epoch 49/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.9282 - accuracy: 0.6167 - val_loss: 0.9624 - val_accuracy: 0.4000\n",
            "Epoch 50/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.9248 - accuracy: 0.6333 - val_loss: 0.9597 - val_accuracy: 0.4333\n",
            "Epoch 51/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.9214 - accuracy: 0.6667 - val_loss: 0.9568 - val_accuracy: 0.4333\n",
            "Epoch 52/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.9183 - accuracy: 0.6750 - val_loss: 0.9543 - val_accuracy: 0.4333\n",
            "Epoch 53/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.9150 - accuracy: 0.6917 - val_loss: 0.9513 - val_accuracy: 0.4667\n",
            "Epoch 54/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.9117 - accuracy: 0.7167 - val_loss: 0.9487 - val_accuracy: 0.4667\n",
            "Epoch 55/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.9084 - accuracy: 0.7333 - val_loss: 0.9462 - val_accuracy: 0.5333\n",
            "Epoch 56/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.9052 - accuracy: 0.7333 - val_loss: 0.9434 - val_accuracy: 0.5333\n",
            "Epoch 57/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.9020 - accuracy: 0.7417 - val_loss: 0.9406 - val_accuracy: 0.5667\n",
            "Epoch 58/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.8989 - accuracy: 0.7333 - val_loss: 0.9381 - val_accuracy: 0.5667\n",
            "Epoch 59/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.8956 - accuracy: 0.7417 - val_loss: 0.9355 - val_accuracy: 0.5667\n",
            "Epoch 60/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.8925 - accuracy: 0.7500 - val_loss: 0.9327 - val_accuracy: 0.6000\n",
            "Epoch 61/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.8893 - accuracy: 0.7500 - val_loss: 0.9300 - val_accuracy: 0.6000\n",
            "Epoch 62/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.8860 - accuracy: 0.7500 - val_loss: 0.9270 - val_accuracy: 0.6000\n",
            "Epoch 63/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.8828 - accuracy: 0.7500 - val_loss: 0.9238 - val_accuracy: 0.6000\n",
            "Epoch 64/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.8797 - accuracy: 0.7667 - val_loss: 0.9204 - val_accuracy: 0.6000\n",
            "Epoch 65/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.8765 - accuracy: 0.7833 - val_loss: 0.9174 - val_accuracy: 0.6000\n",
            "Epoch 66/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.8733 - accuracy: 0.7833 - val_loss: 0.9150 - val_accuracy: 0.6333\n",
            "Epoch 67/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.8701 - accuracy: 0.7917 - val_loss: 0.9123 - val_accuracy: 0.6333\n",
            "Epoch 68/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.8669 - accuracy: 0.8000 - val_loss: 0.9097 - val_accuracy: 0.7000\n",
            "Epoch 69/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.8635 - accuracy: 0.8000 - val_loss: 0.9066 - val_accuracy: 0.7000\n",
            "Epoch 70/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.8603 - accuracy: 0.8000 - val_loss: 0.9037 - val_accuracy: 0.7000\n",
            "Epoch 71/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.8571 - accuracy: 0.8000 - val_loss: 0.9006 - val_accuracy: 0.7000\n",
            "Epoch 72/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.8538 - accuracy: 0.8083 - val_loss: 0.8974 - val_accuracy: 0.7000\n",
            "Epoch 73/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.8506 - accuracy: 0.8083 - val_loss: 0.8940 - val_accuracy: 0.7000\n",
            "Epoch 74/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.8474 - accuracy: 0.8167 - val_loss: 0.8909 - val_accuracy: 0.7000\n",
            "Epoch 75/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.8442 - accuracy: 0.8167 - val_loss: 0.8876 - val_accuracy: 0.7000\n",
            "Epoch 76/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.8408 - accuracy: 0.8167 - val_loss: 0.8849 - val_accuracy: 0.7000\n",
            "Epoch 77/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.8376 - accuracy: 0.8167 - val_loss: 0.8824 - val_accuracy: 0.7000\n",
            "Epoch 78/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.8343 - accuracy: 0.8167 - val_loss: 0.8796 - val_accuracy: 0.7000\n",
            "Epoch 79/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.8315 - accuracy: 0.8167 - val_loss: 0.8773 - val_accuracy: 0.7000\n",
            "Epoch 80/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.8279 - accuracy: 0.8083 - val_loss: 0.8744 - val_accuracy: 0.7000\n",
            "Epoch 81/300\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.8250 - accuracy: 0.8167 - val_loss: 0.8708 - val_accuracy: 0.7000\n",
            "Epoch 82/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.8218 - accuracy: 0.8167 - val_loss: 0.8684 - val_accuracy: 0.7333\n",
            "Epoch 83/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.8184 - accuracy: 0.8000 - val_loss: 0.8658 - val_accuracy: 0.7333\n",
            "Epoch 84/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.8152 - accuracy: 0.8167 - val_loss: 0.8622 - val_accuracy: 0.7667\n",
            "Epoch 85/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.8120 - accuracy: 0.8167 - val_loss: 0.8594 - val_accuracy: 0.7667\n",
            "Epoch 86/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.8087 - accuracy: 0.8167 - val_loss: 0.8560 - val_accuracy: 0.7667\n",
            "Epoch 87/300\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.8055 - accuracy: 0.8167 - val_loss: 0.8528 - val_accuracy: 0.7667\n",
            "Epoch 88/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.8024 - accuracy: 0.8167 - val_loss: 0.8495 - val_accuracy: 0.7667\n",
            "Epoch 89/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7992 - accuracy: 0.8167 - val_loss: 0.8461 - val_accuracy: 0.7667\n",
            "Epoch 90/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7960 - accuracy: 0.8167 - val_loss: 0.8429 - val_accuracy: 0.8000\n",
            "Epoch 91/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7930 - accuracy: 0.8167 - val_loss: 0.8402 - val_accuracy: 0.7667\n",
            "Epoch 92/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.7897 - accuracy: 0.8167 - val_loss: 0.8370 - val_accuracy: 0.8000\n",
            "Epoch 93/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.7867 - accuracy: 0.8167 - val_loss: 0.8341 - val_accuracy: 0.8000\n",
            "Epoch 94/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7835 - accuracy: 0.8167 - val_loss: 0.8309 - val_accuracy: 0.8000\n",
            "Epoch 95/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7802 - accuracy: 0.8167 - val_loss: 0.8277 - val_accuracy: 0.8000\n",
            "Epoch 96/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7772 - accuracy: 0.8167 - val_loss: 0.8246 - val_accuracy: 0.8000\n",
            "Epoch 97/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7740 - accuracy: 0.8167 - val_loss: 0.8218 - val_accuracy: 0.8000\n",
            "Epoch 98/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.7710 - accuracy: 0.8167 - val_loss: 0.8190 - val_accuracy: 0.8000\n",
            "Epoch 99/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7678 - accuracy: 0.8167 - val_loss: 0.8163 - val_accuracy: 0.8000\n",
            "Epoch 100/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7648 - accuracy: 0.8167 - val_loss: 0.8135 - val_accuracy: 0.8000\n",
            "Epoch 101/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7617 - accuracy: 0.8167 - val_loss: 0.8107 - val_accuracy: 0.8000\n",
            "Epoch 102/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7589 - accuracy: 0.8167 - val_loss: 0.8081 - val_accuracy: 0.8000\n",
            "Epoch 103/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7557 - accuracy: 0.8167 - val_loss: 0.8054 - val_accuracy: 0.8000\n",
            "Epoch 104/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.7527 - accuracy: 0.8167 - val_loss: 0.8025 - val_accuracy: 0.8000\n",
            "Epoch 105/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7499 - accuracy: 0.8167 - val_loss: 0.8002 - val_accuracy: 0.8000\n",
            "Epoch 106/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7467 - accuracy: 0.8167 - val_loss: 0.7973 - val_accuracy: 0.8000\n",
            "Epoch 107/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7440 - accuracy: 0.8250 - val_loss: 0.7941 - val_accuracy: 0.8000\n",
            "Epoch 108/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.7410 - accuracy: 0.8250 - val_loss: 0.7914 - val_accuracy: 0.8000\n",
            "Epoch 109/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7381 - accuracy: 0.8250 - val_loss: 0.7889 - val_accuracy: 0.8000\n",
            "Epoch 110/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.7353 - accuracy: 0.8250 - val_loss: 0.7866 - val_accuracy: 0.8000\n",
            "Epoch 111/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.7325 - accuracy: 0.8250 - val_loss: 0.7838 - val_accuracy: 0.8000\n",
            "Epoch 112/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7297 - accuracy: 0.8250 - val_loss: 0.7814 - val_accuracy: 0.8000\n",
            "Epoch 113/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7269 - accuracy: 0.8250 - val_loss: 0.7789 - val_accuracy: 0.8000\n",
            "Epoch 114/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.7243 - accuracy: 0.8250 - val_loss: 0.7766 - val_accuracy: 0.8000\n",
            "Epoch 115/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7219 - accuracy: 0.8167 - val_loss: 0.7744 - val_accuracy: 0.8000\n",
            "Epoch 116/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.7191 - accuracy: 0.8167 - val_loss: 0.7713 - val_accuracy: 0.8000\n",
            "Epoch 117/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7163 - accuracy: 0.8333 - val_loss: 0.7688 - val_accuracy: 0.8000\n",
            "Epoch 118/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7138 - accuracy: 0.8333 - val_loss: 0.7663 - val_accuracy: 0.8000\n",
            "Epoch 119/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7111 - accuracy: 0.8333 - val_loss: 0.7640 - val_accuracy: 0.8000\n",
            "Epoch 120/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7087 - accuracy: 0.8333 - val_loss: 0.7618 - val_accuracy: 0.8000\n",
            "Epoch 121/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.7061 - accuracy: 0.8333 - val_loss: 0.7595 - val_accuracy: 0.8000\n",
            "Epoch 122/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.7040 - accuracy: 0.8167 - val_loss: 0.7575 - val_accuracy: 0.8000\n",
            "Epoch 123/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7012 - accuracy: 0.8167 - val_loss: 0.7549 - val_accuracy: 0.8000\n",
            "Epoch 124/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6989 - accuracy: 0.8333 - val_loss: 0.7521 - val_accuracy: 0.8333\n",
            "Epoch 125/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6964 - accuracy: 0.8417 - val_loss: 0.7496 - val_accuracy: 0.8333\n",
            "Epoch 126/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6940 - accuracy: 0.8417 - val_loss: 0.7473 - val_accuracy: 0.8333\n",
            "Epoch 127/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6917 - accuracy: 0.8417 - val_loss: 0.7448 - val_accuracy: 0.8333\n",
            "Epoch 128/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6894 - accuracy: 0.8417 - val_loss: 0.7424 - val_accuracy: 0.8333\n",
            "Epoch 129/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6870 - accuracy: 0.8417 - val_loss: 0.7404 - val_accuracy: 0.8333\n",
            "Epoch 130/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6846 - accuracy: 0.8417 - val_loss: 0.7382 - val_accuracy: 0.8333\n",
            "Epoch 131/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6824 - accuracy: 0.8417 - val_loss: 0.7364 - val_accuracy: 0.8333\n",
            "Epoch 132/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6803 - accuracy: 0.8417 - val_loss: 0.7346 - val_accuracy: 0.8333\n",
            "Epoch 133/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6779 - accuracy: 0.8333 - val_loss: 0.7322 - val_accuracy: 0.8333\n",
            "Epoch 134/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6756 - accuracy: 0.8333 - val_loss: 0.7297 - val_accuracy: 0.8333\n",
            "Epoch 135/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6734 - accuracy: 0.8500 - val_loss: 0.7274 - val_accuracy: 0.8333\n",
            "Epoch 136/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6711 - accuracy: 0.8500 - val_loss: 0.7254 - val_accuracy: 0.8333\n",
            "Epoch 137/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6690 - accuracy: 0.8500 - val_loss: 0.7235 - val_accuracy: 0.8333\n",
            "Epoch 138/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6668 - accuracy: 0.8500 - val_loss: 0.7214 - val_accuracy: 0.8333\n",
            "Epoch 139/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6647 - accuracy: 0.8500 - val_loss: 0.7193 - val_accuracy: 0.8333\n",
            "Epoch 140/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6625 - accuracy: 0.8417 - val_loss: 0.7174 - val_accuracy: 0.8333\n",
            "Epoch 141/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6603 - accuracy: 0.8500 - val_loss: 0.7153 - val_accuracy: 0.8333\n",
            "Epoch 142/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6584 - accuracy: 0.8417 - val_loss: 0.7135 - val_accuracy: 0.8333\n",
            "Epoch 143/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6561 - accuracy: 0.8500 - val_loss: 0.7110 - val_accuracy: 0.8333\n",
            "Epoch 144/300\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.6541 - accuracy: 0.8500 - val_loss: 0.7086 - val_accuracy: 0.8667\n",
            "Epoch 145/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6520 - accuracy: 0.8500 - val_loss: 0.7066 - val_accuracy: 0.8667\n",
            "Epoch 146/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6499 - accuracy: 0.8500 - val_loss: 0.7045 - val_accuracy: 0.8667\n",
            "Epoch 147/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6478 - accuracy: 0.8500 - val_loss: 0.7025 - val_accuracy: 0.8667\n",
            "Epoch 148/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6457 - accuracy: 0.8500 - val_loss: 0.7006 - val_accuracy: 0.8667\n",
            "Epoch 149/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6438 - accuracy: 0.8500 - val_loss: 0.6983 - val_accuracy: 0.8667\n",
            "Epoch 150/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6418 - accuracy: 0.8500 - val_loss: 0.6961 - val_accuracy: 0.8667\n",
            "Epoch 151/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6397 - accuracy: 0.8500 - val_loss: 0.6942 - val_accuracy: 0.8667\n",
            "Epoch 152/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6378 - accuracy: 0.8500 - val_loss: 0.6927 - val_accuracy: 0.8667\n",
            "Epoch 153/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6357 - accuracy: 0.8500 - val_loss: 0.6906 - val_accuracy: 0.8667\n",
            "Epoch 154/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6337 - accuracy: 0.8500 - val_loss: 0.6885 - val_accuracy: 0.8667\n",
            "Epoch 155/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6317 - accuracy: 0.8500 - val_loss: 0.6866 - val_accuracy: 0.8667\n",
            "Epoch 156/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6299 - accuracy: 0.8500 - val_loss: 0.6846 - val_accuracy: 0.8667\n",
            "Epoch 157/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6278 - accuracy: 0.8500 - val_loss: 0.6826 - val_accuracy: 0.8667\n",
            "Epoch 158/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6260 - accuracy: 0.8583 - val_loss: 0.6807 - val_accuracy: 0.8667\n",
            "Epoch 159/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6239 - accuracy: 0.8500 - val_loss: 0.6791 - val_accuracy: 0.8667\n",
            "Epoch 160/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6223 - accuracy: 0.8500 - val_loss: 0.6778 - val_accuracy: 0.8667\n",
            "Epoch 161/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6205 - accuracy: 0.8500 - val_loss: 0.6755 - val_accuracy: 0.8667\n",
            "Epoch 162/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6182 - accuracy: 0.8583 - val_loss: 0.6739 - val_accuracy: 0.8667\n",
            "Epoch 163/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6164 - accuracy: 0.8500 - val_loss: 0.6720 - val_accuracy: 0.8667\n",
            "Epoch 164/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6145 - accuracy: 0.8583 - val_loss: 0.6701 - val_accuracy: 0.8667\n",
            "Epoch 165/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6129 - accuracy: 0.8583 - val_loss: 0.6686 - val_accuracy: 0.8667\n",
            "Epoch 166/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6110 - accuracy: 0.8583 - val_loss: 0.6662 - val_accuracy: 0.9000\n",
            "Epoch 167/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6089 - accuracy: 0.8583 - val_loss: 0.6645 - val_accuracy: 0.9000\n",
            "Epoch 168/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6071 - accuracy: 0.8583 - val_loss: 0.6625 - val_accuracy: 0.9000\n",
            "Epoch 169/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6052 - accuracy: 0.8583 - val_loss: 0.6607 - val_accuracy: 0.9000\n",
            "Epoch 170/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6036 - accuracy: 0.8583 - val_loss: 0.6590 - val_accuracy: 0.9000\n",
            "Epoch 171/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6017 - accuracy: 0.8583 - val_loss: 0.6570 - val_accuracy: 0.9000\n",
            "Epoch 172/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6002 - accuracy: 0.8667 - val_loss: 0.6546 - val_accuracy: 0.8667\n",
            "Epoch 173/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5981 - accuracy: 0.8667 - val_loss: 0.6527 - val_accuracy: 0.8667\n",
            "Epoch 174/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5963 - accuracy: 0.8667 - val_loss: 0.6509 - val_accuracy: 0.8667\n",
            "Epoch 175/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5947 - accuracy: 0.8667 - val_loss: 0.6488 - val_accuracy: 0.8667\n",
            "Epoch 176/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5929 - accuracy: 0.8667 - val_loss: 0.6469 - val_accuracy: 0.9000\n",
            "Epoch 177/300\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.5912 - accuracy: 0.8750 - val_loss: 0.6452 - val_accuracy: 0.9000\n",
            "Epoch 178/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5894 - accuracy: 0.8667 - val_loss: 0.6437 - val_accuracy: 0.8667\n",
            "Epoch 179/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.5879 - accuracy: 0.8667 - val_loss: 0.6423 - val_accuracy: 0.8667\n",
            "Epoch 180/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5860 - accuracy: 0.8667 - val_loss: 0.6408 - val_accuracy: 0.8667\n",
            "Epoch 181/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5844 - accuracy: 0.8667 - val_loss: 0.6389 - val_accuracy: 0.8667\n",
            "Epoch 182/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5825 - accuracy: 0.8667 - val_loss: 0.6374 - val_accuracy: 0.8667\n",
            "Epoch 183/300\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.5809 - accuracy: 0.8667 - val_loss: 0.6358 - val_accuracy: 0.8667\n",
            "Epoch 184/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5793 - accuracy: 0.8667 - val_loss: 0.6341 - val_accuracy: 0.8667\n",
            "Epoch 185/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5775 - accuracy: 0.8667 - val_loss: 0.6326 - val_accuracy: 0.8667\n",
            "Epoch 186/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5763 - accuracy: 0.8667 - val_loss: 0.6306 - val_accuracy: 0.8667\n",
            "Epoch 187/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5742 - accuracy: 0.8667 - val_loss: 0.6292 - val_accuracy: 0.8667\n",
            "Epoch 188/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5726 - accuracy: 0.8667 - val_loss: 0.6278 - val_accuracy: 0.8667\n",
            "Epoch 189/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5709 - accuracy: 0.8667 - val_loss: 0.6262 - val_accuracy: 0.8667\n",
            "Epoch 190/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5693 - accuracy: 0.8667 - val_loss: 0.6245 - val_accuracy: 0.8667\n",
            "Epoch 191/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5679 - accuracy: 0.8667 - val_loss: 0.6232 - val_accuracy: 0.8667\n",
            "Epoch 192/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5662 - accuracy: 0.8667 - val_loss: 0.6212 - val_accuracy: 0.8667\n",
            "Epoch 193/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5645 - accuracy: 0.8750 - val_loss: 0.6195 - val_accuracy: 0.8667\n",
            "Epoch 194/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5629 - accuracy: 0.8750 - val_loss: 0.6180 - val_accuracy: 0.8667\n",
            "Epoch 195/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5614 - accuracy: 0.8667 - val_loss: 0.6165 - val_accuracy: 0.8667\n",
            "Epoch 196/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5598 - accuracy: 0.8750 - val_loss: 0.6148 - val_accuracy: 0.8667\n",
            "Epoch 197/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5582 - accuracy: 0.8750 - val_loss: 0.6131 - val_accuracy: 0.8667\n",
            "Epoch 198/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.5565 - accuracy: 0.8750 - val_loss: 0.6114 - val_accuracy: 0.9000\n",
            "Epoch 199/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5550 - accuracy: 0.8750 - val_loss: 0.6097 - val_accuracy: 0.9000\n",
            "Epoch 200/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5534 - accuracy: 0.8750 - val_loss: 0.6081 - val_accuracy: 0.9000\n",
            "Epoch 201/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5519 - accuracy: 0.8833 - val_loss: 0.6066 - val_accuracy: 0.9000\n",
            "Epoch 202/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5503 - accuracy: 0.8833 - val_loss: 0.6051 - val_accuracy: 0.9000\n",
            "Epoch 203/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5487 - accuracy: 0.8750 - val_loss: 0.6036 - val_accuracy: 0.9000\n",
            "Epoch 204/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5473 - accuracy: 0.8750 - val_loss: 0.6023 - val_accuracy: 0.8667\n",
            "Epoch 205/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5458 - accuracy: 0.8750 - val_loss: 0.6008 - val_accuracy: 0.8667\n",
            "Epoch 206/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5445 - accuracy: 0.8750 - val_loss: 0.5988 - val_accuracy: 0.9000\n",
            "Epoch 207/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5427 - accuracy: 0.8833 - val_loss: 0.5975 - val_accuracy: 0.9000\n",
            "Epoch 208/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5412 - accuracy: 0.8833 - val_loss: 0.5960 - val_accuracy: 0.9000\n",
            "Epoch 209/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5398 - accuracy: 0.8833 - val_loss: 0.5943 - val_accuracy: 0.9000\n",
            "Epoch 210/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5383 - accuracy: 0.8917 - val_loss: 0.5928 - val_accuracy: 0.9000\n",
            "Epoch 211/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5367 - accuracy: 0.8917 - val_loss: 0.5913 - val_accuracy: 0.9000\n",
            "Epoch 212/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5352 - accuracy: 0.8917 - val_loss: 0.5897 - val_accuracy: 0.9000\n",
            "Epoch 213/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5338 - accuracy: 0.8917 - val_loss: 0.5881 - val_accuracy: 0.9000\n",
            "Epoch 214/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5324 - accuracy: 0.8917 - val_loss: 0.5864 - val_accuracy: 0.9000\n",
            "Epoch 215/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5309 - accuracy: 0.8917 - val_loss: 0.5849 - val_accuracy: 0.9000\n",
            "Epoch 216/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5294 - accuracy: 0.8917 - val_loss: 0.5836 - val_accuracy: 0.9000\n",
            "Epoch 217/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5279 - accuracy: 0.8917 - val_loss: 0.5824 - val_accuracy: 0.9000\n",
            "Epoch 218/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5265 - accuracy: 0.8917 - val_loss: 0.5811 - val_accuracy: 0.9000\n",
            "Epoch 219/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5253 - accuracy: 0.8917 - val_loss: 0.5800 - val_accuracy: 0.9000\n",
            "Epoch 220/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5237 - accuracy: 0.8917 - val_loss: 0.5786 - val_accuracy: 0.9000\n",
            "Epoch 221/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5223 - accuracy: 0.8917 - val_loss: 0.5770 - val_accuracy: 0.9000\n",
            "Epoch 222/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.5212 - accuracy: 0.8917 - val_loss: 0.5752 - val_accuracy: 0.9000\n",
            "Epoch 223/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5195 - accuracy: 0.8917 - val_loss: 0.5737 - val_accuracy: 0.9000\n",
            "Epoch 224/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5181 - accuracy: 0.8917 - val_loss: 0.5723 - val_accuracy: 0.9000\n",
            "Epoch 225/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5167 - accuracy: 0.8917 - val_loss: 0.5710 - val_accuracy: 0.9000\n",
            "Epoch 226/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5154 - accuracy: 0.8917 - val_loss: 0.5694 - val_accuracy: 0.9000\n",
            "Epoch 227/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5140 - accuracy: 0.8917 - val_loss: 0.5682 - val_accuracy: 0.9000\n",
            "Epoch 228/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5125 - accuracy: 0.8917 - val_loss: 0.5668 - val_accuracy: 0.9000\n",
            "Epoch 229/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5112 - accuracy: 0.8917 - val_loss: 0.5654 - val_accuracy: 0.9000\n",
            "Epoch 230/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5099 - accuracy: 0.8917 - val_loss: 0.5638 - val_accuracy: 0.9000\n",
            "Epoch 231/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5086 - accuracy: 0.8917 - val_loss: 0.5622 - val_accuracy: 0.9000\n",
            "Epoch 232/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5074 - accuracy: 0.8917 - val_loss: 0.5606 - val_accuracy: 0.9000\n",
            "Epoch 233/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5058 - accuracy: 0.8917 - val_loss: 0.5593 - val_accuracy: 0.9000\n",
            "Epoch 234/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5044 - accuracy: 0.8917 - val_loss: 0.5583 - val_accuracy: 0.9000\n",
            "Epoch 235/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5031 - accuracy: 0.8917 - val_loss: 0.5574 - val_accuracy: 0.9000\n",
            "Epoch 236/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5020 - accuracy: 0.8917 - val_loss: 0.5559 - val_accuracy: 0.9000\n",
            "Epoch 237/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5006 - accuracy: 0.8917 - val_loss: 0.5550 - val_accuracy: 0.9000\n",
            "Epoch 238/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4994 - accuracy: 0.8917 - val_loss: 0.5539 - val_accuracy: 0.9000\n",
            "Epoch 239/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4979 - accuracy: 0.8917 - val_loss: 0.5522 - val_accuracy: 0.9000\n",
            "Epoch 240/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4966 - accuracy: 0.8917 - val_loss: 0.5506 - val_accuracy: 0.9000\n",
            "Epoch 241/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4952 - accuracy: 0.8917 - val_loss: 0.5492 - val_accuracy: 0.9000\n",
            "Epoch 242/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4942 - accuracy: 0.8917 - val_loss: 0.5480 - val_accuracy: 0.9000\n",
            "Epoch 243/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4928 - accuracy: 0.8917 - val_loss: 0.5463 - val_accuracy: 0.9000\n",
            "Epoch 244/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4914 - accuracy: 0.9000 - val_loss: 0.5448 - val_accuracy: 0.9000\n",
            "Epoch 245/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4901 - accuracy: 0.9000 - val_loss: 0.5434 - val_accuracy: 0.9000\n",
            "Epoch 246/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4889 - accuracy: 0.9000 - val_loss: 0.5423 - val_accuracy: 0.9000\n",
            "Epoch 247/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4876 - accuracy: 0.9000 - val_loss: 0.5408 - val_accuracy: 0.9000\n",
            "Epoch 248/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4863 - accuracy: 0.9000 - val_loss: 0.5397 - val_accuracy: 0.9000\n",
            "Epoch 249/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4850 - accuracy: 0.9000 - val_loss: 0.5384 - val_accuracy: 0.9000\n",
            "Epoch 250/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4838 - accuracy: 0.9000 - val_loss: 0.5371 - val_accuracy: 0.9000\n",
            "Epoch 251/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4826 - accuracy: 0.9000 - val_loss: 0.5359 - val_accuracy: 0.9000\n",
            "Epoch 252/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4813 - accuracy: 0.9000 - val_loss: 0.5345 - val_accuracy: 0.9000\n",
            "Epoch 253/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4800 - accuracy: 0.9083 - val_loss: 0.5332 - val_accuracy: 0.9000\n",
            "Epoch 254/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4788 - accuracy: 0.9083 - val_loss: 0.5319 - val_accuracy: 0.9000\n",
            "Epoch 255/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4775 - accuracy: 0.9083 - val_loss: 0.5305 - val_accuracy: 0.9333\n",
            "Epoch 256/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4767 - accuracy: 0.9083 - val_loss: 0.5295 - val_accuracy: 0.9000\n",
            "Epoch 257/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4751 - accuracy: 0.9083 - val_loss: 0.5281 - val_accuracy: 0.9333\n",
            "Epoch 258/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4738 - accuracy: 0.9083 - val_loss: 0.5266 - val_accuracy: 0.9333\n",
            "Epoch 259/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4727 - accuracy: 0.9000 - val_loss: 0.5254 - val_accuracy: 0.9333\n",
            "Epoch 260/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4717 - accuracy: 0.9000 - val_loss: 0.5239 - val_accuracy: 0.9333\n",
            "Epoch 261/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4706 - accuracy: 0.9083 - val_loss: 0.5225 - val_accuracy: 0.9333\n",
            "Epoch 262/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4693 - accuracy: 0.9167 - val_loss: 0.5214 - val_accuracy: 0.9333\n",
            "Epoch 263/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4679 - accuracy: 0.9000 - val_loss: 0.5203 - val_accuracy: 0.9333\n",
            "Epoch 264/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4667 - accuracy: 0.9000 - val_loss: 0.5190 - val_accuracy: 0.9333\n",
            "Epoch 265/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4655 - accuracy: 0.9083 - val_loss: 0.5178 - val_accuracy: 0.9333\n",
            "Epoch 266/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4643 - accuracy: 0.9167 - val_loss: 0.5165 - val_accuracy: 0.9333\n",
            "Epoch 267/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4631 - accuracy: 0.9167 - val_loss: 0.5153 - val_accuracy: 0.9333\n",
            "Epoch 268/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4619 - accuracy: 0.9167 - val_loss: 0.5141 - val_accuracy: 0.9333\n",
            "Epoch 269/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4607 - accuracy: 0.9167 - val_loss: 0.5129 - val_accuracy: 0.9333\n",
            "Epoch 270/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4597 - accuracy: 0.9167 - val_loss: 0.5117 - val_accuracy: 0.9333\n",
            "Epoch 271/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4584 - accuracy: 0.9167 - val_loss: 0.5105 - val_accuracy: 0.9333\n",
            "Epoch 272/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4573 - accuracy: 0.9167 - val_loss: 0.5095 - val_accuracy: 0.9333\n",
            "Epoch 273/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4562 - accuracy: 0.9167 - val_loss: 0.5085 - val_accuracy: 0.9333\n",
            "Epoch 274/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4550 - accuracy: 0.9167 - val_loss: 0.5072 - val_accuracy: 0.9333\n",
            "Epoch 275/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4538 - accuracy: 0.9167 - val_loss: 0.5060 - val_accuracy: 0.9333\n",
            "Epoch 276/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4530 - accuracy: 0.9167 - val_loss: 0.5049 - val_accuracy: 0.9333\n",
            "Epoch 277/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4515 - accuracy: 0.9167 - val_loss: 0.5036 - val_accuracy: 0.9333\n",
            "Epoch 278/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4503 - accuracy: 0.9167 - val_loss: 0.5024 - val_accuracy: 0.9333\n",
            "Epoch 279/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4493 - accuracy: 0.9167 - val_loss: 0.5010 - val_accuracy: 0.9333\n",
            "Epoch 280/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4482 - accuracy: 0.9167 - val_loss: 0.4998 - val_accuracy: 0.9333\n",
            "Epoch 281/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4471 - accuracy: 0.9167 - val_loss: 0.4986 - val_accuracy: 0.9333\n",
            "Epoch 282/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4458 - accuracy: 0.9167 - val_loss: 0.4976 - val_accuracy: 0.9333\n",
            "Epoch 283/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4449 - accuracy: 0.9167 - val_loss: 0.4964 - val_accuracy: 0.9333\n",
            "Epoch 284/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4437 - accuracy: 0.9167 - val_loss: 0.4954 - val_accuracy: 0.9333\n",
            "Epoch 285/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4426 - accuracy: 0.9167 - val_loss: 0.4942 - val_accuracy: 0.9333\n",
            "Epoch 286/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4414 - accuracy: 0.9167 - val_loss: 0.4931 - val_accuracy: 0.9333\n",
            "Epoch 287/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4404 - accuracy: 0.9167 - val_loss: 0.4920 - val_accuracy: 0.9333\n",
            "Epoch 288/300\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4392 - accuracy: 0.9167 - val_loss: 0.4910 - val_accuracy: 0.9333\n",
            "Epoch 289/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4381 - accuracy: 0.9167 - val_loss: 0.4899 - val_accuracy: 0.9333\n",
            "Epoch 290/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4371 - accuracy: 0.9167 - val_loss: 0.4889 - val_accuracy: 0.9333\n",
            "Epoch 291/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4362 - accuracy: 0.9167 - val_loss: 0.4875 - val_accuracy: 0.9333\n",
            "Epoch 292/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4349 - accuracy: 0.9167 - val_loss: 0.4864 - val_accuracy: 0.9333\n",
            "Epoch 293/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4338 - accuracy: 0.9167 - val_loss: 0.4852 - val_accuracy: 0.9333\n",
            "Epoch 294/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4327 - accuracy: 0.9167 - val_loss: 0.4842 - val_accuracy: 0.9333\n",
            "Epoch 295/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4315 - accuracy: 0.9167 - val_loss: 0.4830 - val_accuracy: 0.9333\n",
            "Epoch 296/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4306 - accuracy: 0.9167 - val_loss: 0.4819 - val_accuracy: 0.9333\n",
            "Epoch 297/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4295 - accuracy: 0.9167 - val_loss: 0.4807 - val_accuracy: 0.9333\n",
            "Epoch 298/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4283 - accuracy: 0.9083 - val_loss: 0.4795 - val_accuracy: 0.9333\n",
            "Epoch 299/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4273 - accuracy: 0.9083 - val_loss: 0.4783 - val_accuracy: 0.9333\n",
            "Epoch 300/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4263 - accuracy: 0.9083 - val_loss: 0.4771 - val_accuracy: 0.9333\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2dd0ec8910>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAQlvsoZPmQJ"
      },
      "source": [
        "## Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VT1diaCKPeLA"
      },
      "source": [
        "metrics = pd.DataFrame(model.history.history)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "56dZ9X-FPpzI",
        "outputId": "1d719a00-b60e-4eb5-a68f-915db6766041"
      },
      "source": [
        "metrics.head()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.122380</td>\n",
              "      <td>0.058333</td>\n",
              "      <td>1.143848</td>\n",
              "      <td>0.033333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.117274</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>1.138028</td>\n",
              "      <td>0.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.112324</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>1.133032</td>\n",
              "      <td>0.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.107258</td>\n",
              "      <td>0.191667</td>\n",
              "      <td>1.128244</td>\n",
              "      <td>0.133333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.102564</td>\n",
              "      <td>0.283333</td>\n",
              "      <td>1.123644</td>\n",
              "      <td>0.166667</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       loss  accuracy  val_loss  val_accuracy\n",
              "0  1.122380  0.058333  1.143848      0.033333\n",
              "1  1.117274  0.100000  1.138028      0.100000\n",
              "2  1.112324  0.125000  1.133032      0.100000\n",
              "3  1.107258  0.191667  1.128244      0.133333\n",
              "4  1.102564  0.283333  1.123644      0.166667"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "bKvFo-vQPrE5",
        "outputId": "2dfe1e74-a4cb-4fca-b094-b91b203738f3"
      },
      "source": [
        "metrics[['loss','val_loss']].plot()\n",
        "plt.show()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "YCQqsuRXPtPh",
        "outputId": "0fc09e39-fcf7-43ab-fe04-e6e44987c7e6"
      },
      "source": [
        "metrics[['accuracy','val_accuracy']].plot()\n",
        "plt.show()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxU1f3/8dfJZF/IypIFCKuELWyCiIKCtLjiUoRWrVKVqtWvy6+1uFSp9dfaqm3197Va2rrVhda1aBUVAXEDBdkDhCwsCSH7nkySmTm/P+4kmYSETJKZTO7weT4eeczMXc/N6JuTc889R2mtEUIIYX4Bvi6AEEIIz5BAF0IIPyGBLoQQfkICXQgh/IQEuhBC+IlAX504ISFBp6am+ur0QghhStu3by/RWg/saJ3PAj01NZVt27b56vRCCGFKSqkjna2TJhchhPATEuhCCOEnJNCFEMJPSKALIYSfkEAXQgg/IYEuhBB+QgJdCCH8hM/6oQshRK9kfQoxw6EsG/JM9kzLGYsgebrHDyuBLoQwH63hjRtg7CLI/QxqCgHl61K5L2qIBLoQQgBQWwINVXBitxHmCx6Gc+/xdal8TtrQhRDmU5ZjvBYfMF7jRvquLP2I1NCFEOZTntv2c7tA/92H+4kJC+bW80YBsHpzNmu+OdZXpTtJWLCFx66czKSUaK+eRwJdCGEqWmt0SXab5gVb9PCWMNt+pJy/fpZDXEQwP507kuziGn6/7iATkwYwLD7CF0Xmq6wSHnx3D2/eejYKCFCKgADPt/lLoAshTMPaZOeqZ7/ipuIvuSxAYVGaYj2AMx/5ghvPGcGDF6fx2w/2A1BW28i+41X8eX0m4UEWXlg+k7iIYJ+U+83tefz8jV2MeeBDAB69fCLXnjXc4+eRQBfCkxx2KD4I2t52eVgcRCe3ftYaSrPAEgSxqZ4tQ20pVB8/eXn8aAgKA2sVVHQ6AqtPldU2Ul7X1On6zzKLcBTkcXZsEUWWiSRW76EpOpUL4gfzjy9yCQ4MYPuRcn7+vbE88XEmj398kM2Zxay8cJzPwhzgyqnGd19QUQ9AekqMV84jgS6EJ339DHzyq5OXBwTBzzMhPM74nL0BXrnSeP+zb2DgGZ4rw+p5UNlBe3H6j+CKZ+Ff10DuZs+dz4PinD+dGQX8JASoA2augMxKkkZO5Y/fS+f8xzfx7KZsxg2J4tbzRvPRvkI2ZxaTHBPGDWen9kXxOxUQoPjB9BSvn0cCXQhPKtwLEYPgkj+6LNsHm34HJZkw7KzW7VzXeyrQ6yuMMJ96rdFHu9nnf2w954m9MHohTL8egIr6Jg4WVHvm/L3wWWYRBVVWrps1HFTH7csBCsYnDiA40AKpc2D2zyBkAANCg3jvjnPYnVfJ7JHxWAIUz147jb35VUwfHktokKWPr8Y3JNCF8KSyXBg0DtIubV02MM0I9LLc1kAvy4XAMLDVn9xjozeajzX2Qki7pHV57mbYtcYI/PoyGHEupF1Ko83B5X/6jMOlIZ4rQ48l8OjlE5nWnbblsNiWt0kxYSTFhLV8TokNJyU23JMF7Pck0IXwpLIcGHdx22Uxw0AFtPadbt5u8ASjNu263BPnB4gbAcDGg0V8m1vG9YFJDG6ognzjEfks20DeXneAI6V1HC6t489Lp5A+1Dvtuu4KDQogMTqs6w1FpyTQhfAUaxXUlZz8kEtgMESntK2JN9fWLUHGe09pDvTYVLKLa7jppW3YHZriqEYeB8jaAMC9G2rY2ZiNJUBxxdRkFk9JQnXSzCHMQwJdCE9pDuyOnlqMG9katrYGqMqjJmIY2QW1TLJ+16NHth0OzR8+OkhuSQ23nTeaDQeKOHPXt0ywxPOL1zPIKa4lLMjC766cxJ/X5EMI5G9/n2QgsymBj++ex+hBkT29WtEPSaAL4SntmjvaiB0BGf8x3lccBe3grcNBFBeEkx5UAI11ENy99t63d+Tz3GfZhAdb+Dq7lCqrjbURx8hXQyiotBIeYuH/XjCRS9OTOHT8LBxbFclNRyhTsfyfi6dKmPshCXRxenr3Z3DkC88e01plvMaeHOjH1BCG1pdx/NdjCaaRBOA/R0IYF5YMDjjxu8nYu1lPn+mAr8MV0WFBFFc3EBQWQKIuQU1ayn8vP7fNtvdcOBkOpEDlMeJSzmD5nA7+0RGmJ4EuTj8OO+z+l9FVcPCEbu+u0SiXoVqbP9sdGkfCGdgDwqCp9cEiu0Oz8sAolgbMJynS6D6XYRnAzFEL+PGMBLa9kQtNdd0uh1KKsYMjCQsNpKmolpioEFRYMMy4seMdzn8AcjbChCu7fS5hDkpr7ZMTz5gxQ2/bZrJB6YV/KD8CT02GS59u6Yvtrl+/t489eZWsWXEWgZYAnlp/iHX7TvD9CYP58/pDp9z3uWunsWhiYm9KLgRKqe1a6xkdrZMauvA7eeV1lNU2tnwOUIrxiQOottqICg2kriCTSCDbPojavAq3j1tQaeXFrw6jNTz3WTaTU2L4342HaLJr9hdUcfaoeM4dM7DDfVNiw/j+hCG9vTQhTkkCXfiV0poG5j/5GY02R5vll6Yn8fmhYmaPjGdozsfcD1z7djEFfNmt48dHBDM8PpwnPs4EICLYwpmpMWw/Us7jS9JJjpF+1MJ3JNCFKTgcmo0HizoduCk0KIDvjR/CF1klNNocPLJ4Qku4/nd3AW/vyAfgw70nuD8wH3twMI/+eKHxwE83TEyOJio0kC05pWgNYwdHMWhACEVVDRLmwuck0IUpvPrNUX717t5TbnPD2alUWZuICQ/imlnDsTjHm542LJYvs0u4IG0wmw4Wc25INZbgkSwY3/P27PnjBrf5PDTu9HrEXPRPEuiiXyipaeCFL3NpsrfepI8MCeTW80Zhrauh7qPf8HS8g/POGNTh/t8dKefQtzWkWhQXxYZjWd86mmAs8OU0TWCAwjZFY9l7EGKnefuShOhzEuiiX3ht61Ge2ZhNmHNUPIfWNNgcpCUOIOLwJ/xUv4HDGkLAno5HzZunYZbFjtYQUhUA37Z9jD2wzauCUfO9di1C+IoEuvCqLTmlrN6cg6OT7rHD4sJ58OLxbM4sZnJKNGtvPweARpuDKY98zObMYqYdzzA2vns/RMZ3eBwFSAu2ON1JoAuvqW+0c9eanTTZHaTEnhy3Nodm08Fi4iKC2XGsglvnjWpZFxwYwOyR8Ww8WMREazb1ARGERZxq6gMhhAS6nyqqsvLTV7ZTWGltszw4MICVF6bx6tYj5BTX8qtLxvPaN0fJKvT8BAcNNgeltY38+6ezmTni5DDWWvPj579peSBn7ti2fbjnjh3IpweKGBJ0HGtcKmEyGqAQp+RWoCulFgFPARbg71rrx9qtHwa8BMQ4t1mptf7Aw2UVbmqw2Xn8o4Psza9k8ZRkXGNwS24pt726HYeGqNBAHvtwP4dL65gzOp4kL4xFPWVYTIdhDsaj649dNZlnN2URFRrE9OGxbdYvnpJEVlENE/eXEZV0psfLJoS/6TLQlVIW4BlgIZAHfKuUWqu1znDZ7EHg31rrZ5VS44EPgFQvlFd0Yd/xSpat3kK11cZN54zgwUvGt1n/ZVYJ1/x9K4smDGFgVAj/3GJMFvzEknSfTC6QHBPGo5dP6nBdTHgwv7n0DNh9AhI6GJJWCNGGOzX0mUCW1joHQCm1BlgMuAa6BgY430cDHUw5Lrwlq6iGynrjgZs/rDtAYIDit1dM4sppySdtO2d0Ai/9ZCZTUmL45nAZ/9xyhLGDIzsO87oyCAw1Bo7y5Kw63VFTCA5bx2OMCyHacCfQkwHXKcTzgFnttlkFfKyUugOIAC7wSOlEl97bdZw7Xt/RZtkjiyfwo1nDOt1nnrOtevaoeMKCLCc9JNPipcsgZQYU7ITjOzrepq8MHOfb8wthAp66KfpD4EWt9ZNKqdnAP5VSE7XWbQbUUEqtAFYADBvWeeAI91ib7Dz24QHSEgew8kIj8KJCA5nq5tyQkSGBrLvrXAZFhZ680tYIRfuM6dOK9sOEK4yZ5H0hOAqSp/vm3EKYiDuBng8Mdfmc4lzm6kZgEYDW+mulVCiQABS5bqS1Xg2sBmP43B6WWTi9+NVh8ivqefwHkzl7dEKPjjE8PqLjFZXHQDugYJfR5JF6LoyWP7yE6M/cGZnoW2CMUmqEUioYWAasbbfNUWABgFIqDQgFij1ZUNGqsr6Jxz48wDMbslgwblCPw/yUmicudtiM146mVRNC9CtdBrrW2gbcDnwE7MfozbJPKfWIUuoy52b/B7hZKbULeB24Qftq5ozTwDvf5fHcZ9nERwZz/8Vp3jlJ+5ugclNSiH7PrTZ0Z5/yD9ote8jlfQYwx7NFE53ZfKiE1PhwNv3ifO+dxDXQAwJhQIr3ziWE8IjuDQYtfK7BZufr7NKTnqr0uPLc1smOY4aDRR4qFqK/k/9LTWbb4XLqm+zM7WSqsx755xVQmNF2WV0JjF1k9EGX9nMhTEEC3WQ2ZxYTZFHMHtXxqIPdVlcG2Rtg6Fkw8Iy266ZeC9UnILKTfupCiH5FAt1kPsssZsbwOCJCPPTVlTt7s8z5Hxh3sWeOKYTwCQn0fk5rzZ78SqxNDmobbBw4Uc0vF3nwqcnm7onSi0UI05NA7+ee/jSLP63PbLPs/HEebD9v7s0Sm+q5YwohfEICvR+qabCxL7+S4fERPPtZFhekDWL5HOPGZHRYEOOGDOjiCN1QlgtRSRAk8/0IYXYS6P3QfW/v4b1dx0kfGoPDAQ9fOsF7s8qX5UgvFiH8hPRD70eyi2u4/x0jzAF2Havg+rOHey/MtzwHhfsk0IXwExLo/chfP8tmzTdHmT48lqeWTWFmahy3nz/GOyezVsK6XxrvRy3wzjmEEH1Kmlz6Ca01mzNL+P6EITx7rTFU7OIpJ09Q4THNN0OveBbSLvXeeYQQfUZq6P3EoaIaTlRZvf9If7Pm7oqx0twihL+QQO8nNmcaow33XaA7a+jSfi6E35BA7yf25FeSFB1KckwfdR8syzUe6Q/uZIILIYTpSKD3ExnHqxif5MH+5V0pz5WnQ4XwM3JTtB+wNtnJKall0cQh3d9Za8j/DhprurdfSSaMXtj98wkh+i0J9H4gs7Aau0MzPrEHNfS8bfCPHs71OchLsx0JIXxCAr0f2F9QBUBaTwK9yjlf9+XPGhNRuCvAAknTun8+IUS/JYHeD+w4WkFUaCDDevJEaH258TryPBiQ5MliCSFMRm6K+pjxQFExc0YlEBCgun+A5kAPi/VswYQQpiOB7mPZxTUcr+zFA0X15WAJkdEShRAS6L624UARAHPHJvTsANYKqZ0LIQAJdJ+qbbDx989zmT48lpTYHo6oWF8ugS6EACTQfeqVLUcoqm7g/ot6MaVcvdTQhRAGCXQf2pVXQWp8ONOHx/X8IPXlEBbjuUIJIUxLAt2HjpTWkZrQy7FUpIYuhHCSQPcRrTVHSusY3tvZiKQNXQjhJIHuI2W1jdQ02Bge34sauq0BmmqlyUUIAUig+8zh0joAUhN6UUOvrzBepYYuhEAC3WeOltUCMCyuFzX05qdEQ6WGLoSQQPeZwyV1KAVD43r4hGd9Obx7i/FeauhCCCTQfWZXXgUjEiIICbT07ACH1sPxHRA/BgZP8GzhhBCmJIHuA9YmO1tySpk7phfzhzbPCXrL5xDVg4kxhBB+RwLdB7YdLsfa5Oj5+C1gTCE3IFkG5RJCtJBA94EvskoIsijOGhnf84OU5cicoEKINtwKdKXUIqXUQaVUllJqZSfbXK2UylBK7VNKvebZYvqX3JIaUuMjCA/uxfwiZbkQm+qxMgkhzK/LRFFKWYBngIVAHvCtUmqt1jrDZZsxwH3AHK11uVJqkLcK7A8KKq0kxvSiqaShGmqLpIYuhGjDnSriTCBLa50DoJRaAywGMly2uRl4RmtdDqC1LvJ0Qf1JQaWVtCFuzh9qa4TDn4PD1rqs8pjxKoEuhHDhTqAnA8dcPucBs9ptMxZAKfUlYAFWaa3XtT+QUmoFsAJg2LBhPSmv6TXaHJTUNJAYE+reDrteh/f+p+N1g8Z7rmBCCNPz1CTRgcAY4DwgBdislJqkta5w3UhrvRpYDTBjxgztoXObSmGVFa0hMdrNQC8+CIFhcMN/wXXK0ZBoSBjtlTIKIczJnUDPB4a6fE5xLnOVB2zVWjcBuUqpTIyA/9YjpfQjBZVWABKj3WxDL8+FuBGQMt2LpRJC+AN3erl8C4xRSo1QSgUDy4C17bZ5F6N2jlIqAaMJJseD5fQbBZX1QDdq6NI9UQjhpi4DXWttA24HPgL2A//WWu9TSj2ilLrMudlHQKlSKgPYCPxCa13qrUKbWUsN3Z1eLg6HdE8UQrjNrTZ0rfUHwAftlj3k8l4D9zh/RCfe2ZHH3z/PJSokkMgQN3711QVgb5AauhDCLfKkaB96b1cBjTY7P5vv5s3M5vFa4kZ4r1BCCL/hqV4uwg0FlVbOTI3jlnmjTr3h/vfh7ZuNGYlAauhCCLdIoPehgsp6pg93YzKKw1+A1jDnfyAqCWKGe79wQgjTk0DvI/WNdirqmtzrrliWA/Gj4YJV3i6WEMKPSBt6HzlRZfRuGTLAje6KZTkQl+rdAgkh/I4Eeh8pqHD2P+/qkX+HHSqOSLu5EKLbJND7iNtPiFblg70RYqVnixCieyTQ+4jbT4iW5RqvUkMXQnSTBHof2HCgkLd35BMbHkRo0CkmhS7cB5t+Z7yXvudCiG6SQO8Dj3+USVFVA4unJJ96w71vwdGvYfQFxnyhQgjRDdJt0cuKqq3sL6ji3kVncNt5XTwhWl8O4fFw7Vt9UzghhF+RGrqXfZ5ZAsDcMQO73ri+HMJivVwiIYS/kkD3ss2HikmIDGZ8ohtTzkmgCyF6QQLdixwOzeeHSjh3zEACAlTXO0igCyF6QQLdi/Yer6SstpG5YxPc26G+QgJdCNFjEuheUlLTwMtfHwHgXHfaz0ECXQjRK9LLxQsabQ6WPPc1uSW1TBsWQ0JkSNc72W3QUAmhbozGKIQQHZBA94JXthwht6SWJ5ek8/2JQ9zbyVppvEoNXQjRQxLoHlZZ18TTGw5x7pgErpyWjFJu3AwFsFYYrxLoQogekjZ0D/vLpiwq65u478I098McjB4uIIEuhOgxCXQP+zijkPlnDGJ8khv9zl1JoAshekkC3YNqG2wcLq0lfWgPbmxKoAshekkC3YMOnKhGa0hz56nQ9upKjdcw6eUihOgZCXQP2l9QBUBaYlTrwvWr4O0Vp95x+0uwbqXxPjTaO4UTQvg96eXiAfWNdg6X1rI1t4wBoYEkx7jMSpS9wXhg6FSOfAlhcXDxE2AJ8m5hhRB+SwK9lxptDi793y/IKqoBYM7o+NbeLVo7ZyDqordLWQ4MmQgTr/JuYYUQfk0CvZf+ueUIWUU1PHBRGkPjwpic4tIGXlcKDUYzDA47BHQyW1FZDqRd6v3CCiH8mgR6L1TUNfL0p8ZDRDfP7WAO0Ob5QcF4EjQ87uRtrJVG8MscokKIXpJA76ZP9xfy3VGji+He/CqqrE3cf1FaxxuX5bS+ry/vONCbQz9W5hAVQvSOBHo3HDxRzc0vbwMgwNlOfuu8UZ13Uyx3qaE39zNvrzn0pYYuhOglCfROaK354yeZHDhRjUUpbp47kqc+PURkSCCb7z2fmPBg2PYCRAcD49ruvO8do828fQ3dVe7nsPW51hp6nNTQhRC9I4Heifd2F/D/NmQxcmAEZbWNfJVdQpXVxoMXpxlhDrDhN5A4BcZc0Hbnz580hsMNiYSoJKg+fnKgb38RstZD/BhI/xEER/TJdQkh/JcEegesTXZ+/+EBxicO4P07zuGr7FKu/cdWhsWFc93s4c6NnDczXWvh0NpV0WGH4HAYNhsOHD+5L3pZjrHux+/2zUUJIfyeBDpgd2hsDkfL5xe+PEx+RT2P/2AyAQGKc8YksOrS8UwbHktIoLPrYXNTSeUxsDe1PhBUWwKNRp90bPWQNAUOvH9yDb08FyZc4eUrE0KcTk77QM8rr+OqZ7+isKqhzfL54wZx9ujWuUBvmNOujbu5Zu6wGaHefFOzfY09YSyEDGgb6HVlxme5ESqE8CC3Al0ptQh4CrAAf9daP9bJdlcBbwJnaq23eayUXvTERwepqGvi598b2/KEZ5BF8YPpQ0+9o2twl+V0HuixI4wBt1wDvVy6KgohPK/LQFdKWYBngIVAHvCtUmqt1jqj3XZRwJ3AVm8U1Bt251Xw7s7j/Oz8Udw+f0z3di7PBUsI2BvaPkBUngsqwPhx2IzeK2GxrTMSgUvPFqmhCyE8x50a+kwgS2udA6CUWgMsBjLabfcb4PfALzxaQi/QWvNlVilPfHyQ+Ihgbpk36tQ7HPsGSrNBKRg1H6qOQ952o328YDcc+gSCI41tcz+H6BQICISGagiJMgK9NAt2vm5sc+gj4zU21WvXKIQ4/bgT6MnAMZfPecAs1w2UUtOAoVrr/yqlOg10pdQKYAXAsGHDul9aD/lw7wlue/U7lILfXzmZqNBTjHDosMPLi6Gpzvg84ydwcJ3RFXHmCkAZAd0c0gDjLoGg8NZxXGJHQM4mePeW1m3ixxi9YIQQwkN6fVNUKRUA/BG4oatttdargdUAM2bM0L09d0802hw89uEBzhgcxcs3zmTwgNBT71CVb4T5gocgYy0c32GE+Zy7jGX2Rqg+0XafAclGbV47L/GiJ2DOnW23iRjouYsSQgjcC/R8wPUOYYpzWbMoYCKwyXlTcQiwVil1WX+8MfpVdglHy+r463XTuw5zaL3JmTwDijNh97+Mz0lTjdETA8K6fsrTEihPggohvM6dGYu+BcYopUYopYKBZcDa5pVa60qtdYLWOlVrnQpsAfplmANsziwhJDCAeWPdrCG73sCMGwE4a90S0EKIfqbLQNda24DbgY+A/cC/tdb7lFKPKKUu83YBPW3zoWJmjogjNKiTscnbK8sBSzAMSGrbK0W6HAoh+hm32tC11h8AH7Rb9lAn257X+2J51uGSWu54fQdltY3kV9Sz7Mwu+pi7Ks81eqMEWFpDPDwBQnswEbQQQnjRafGk6G8/2E9OcQ2LJiYSEhTAFVOTT72DvQlszidHS10eGmr/KoQQ/YjfB/re/Eo+zijk598b697DQ7ZG+PMkqHHpuTLyPOM1PA5CYyB+tDeKKoQQveL3gb5+fyFKwTWzhru3Q8VRI8wnXQ1DJhlPfE680linFPxwDUR3UcMXQggf8PtA35xZzOTkaGIjgt3boXmclTNvgmGzTl4/fLbnCieEEB7kV4HeYLPzwZ4CGm3GULh2B+w8VsHPzu9GE0nLlHDSi0UIYS5+Fehvf5fPfW/vOWn5wvGD3T9IWa4xLos8ySmEMBm/CvRNB4tIjgnjjVtam0VCgyzEudvcAkYNPXaE0V4uhBAm4jeB3mR38FVWKZekJ5IUE9bzA5XlwKA0zxVMCCH6iDuP/pvCzmMVVDfYmDumF00lDjtUHJH2cyGEKflNoO84aswINGtkfM8PUpVvjJ4oDw4JIUzIbwI943gVQwaEdq+9vD2ZSUgIYWJ+E+j7C6oZn9TL8VWauyzKwFtCCBPyi0C3NtnJKq4hLTGqdwdqnid0gDwJKoQwH78I9KyiGuwOTVqiB2roscMhwC9+LUKI04xfJFdGgTF35/heB3qutJ8LIUzLL/qhZxyvIizIwvD4iLYrHA7I/hRGX9A6x+fet1onb26vLAdGzPV+gYUQwgv8ItD3F1QxLjEKS0C7pzuPfAmv/gCuf88I6uPfwVs3nvpgSVO9V1AhhPAi0we61pr9BVVckp508sqaQuO15JAR6CVZxufl6zp+eCggECISvFdYIYTwItMHen5FPVVWW8ft5/XGw0Yt3RHLcwEFydMgMKTPyiiEEH3B9DdF9xdUA3Tcw6W+wngtP2y8luVAdIqEuRDCL5k+0E9U1gMwNK6DAbmszkBvrqGXOSd8FkIIP2T6QK9psAMQGdJB61FLk0uu0cOlLEe6JQoh/JbpA722wUaAgrAgy8krmwPdVg/526GuREZSFEL4LdMHek2DjYjgQFRHE1LUl4PFOVjX3xcYr/HdmI5OCCFMxPS9XGobbER01NwCRqCP+R6MuxgaayEoDMZ8v28LKIQQfcT8gd5oIyKkg+YWMHq5hMfBlB/1baGEEMIH/KDJxd7xDVGtjRp6WGzfF0oIIXzA9IHeaZNLUz3YGyTQhRCnDf8N9OYeLqExfVsgIYTwEdMHek2DreMml+aHiqSGLoQ4TZj/pmiD86ZoaTb89x6wNRgrGowhASTQhRCnC9PX0Gsb7EaTy+EvIGeTcTPUEmT0bjnjYkhM93URhRCiT5i6ht5oc9BodxAZHNjaxHLtWxAS6duCCSGED5i6hl7XaAMwauj15RAQBMERXewlhBD+ydSBXtNgBHpkc6CHxRpTzQkhxGnIrUBXSi1SSh1USmUppVZ2sP4epVSGUmq3UupTpdRwzxf1ZLXOkRZbauhh0kVRCHH66jLQlVIW4BngQmA88EOl1Ph2m+0AZmitJwNvAn/wdEE70lxDjwixyFOhQojTnjs19JlAltY6R2vdCKwBFrtuoLXeqLWuc37cAqR4tpgdq+2oyUUIIU5T7gR6MnDM5XOec1lnbgQ+7GiFUmqFUmqbUmpbcXGx+6XsRG2D603RSgl0IcRpzaM3RZVS1wIzgMc7Wq+1Xq21nqG1njFw4MBen++km6LymL8Q4jTmTj/0fGCoy+cU57I2lFIXAA8A87TWDZ4p3qlVW52BHqihsVpq6EKI05o7NfRvgTFKqRFKqWBgGbDWdQOl1FTgr8BlWusizxezYxX1TSgFA1StsUACXQhxGusy0LXWNuB24CNgP/BvrfU+pdQjSqnLnJs9DkQCbyildiql1nZyOI+qqm8iKiQQiwzEJYQQ7j36r7X+APig3bKHXN5f4OFyuaWirpGY8ODWoXIl0IUQpzFTPylaUd9ETHgQlBw0FsiDRUKI05i5A72uifl6K6y9w1gQ0fueM0IIYVamHm2xsr6JccE5oCyw7FWI7ZMRB4TwS01NTeTl5WG1Wn1dFAGEhoaSkpJCUFCQ2/uYOpmvA8MAAA6NSURBVNAr6hpJCiyAmKFwxoW+Lo4QppaXl0dUVBSpqakoGeTOp7TWlJaWkpeXx4gRI9zez7RNLg6HprK+iUFNxyFupK+LI4TpWa1W4uPjJcz7AaUU8fHx3f5rybSBXtNow6E1sQ3HINb9f8GEEJ2TMO8/evJdmDbQK+uaiKGGEFuN1NCFEAITB3pFXRPDVaHxQQJdCCFMHOj1jS6BLk0uQgj32Ww2XxfBK0zby6Wy3qWGHpvq07II4W9+/d4+Mo5XefSY45MG8PClE7rc7vLLL+fYsWNYrVbuvPNOVqxYwbp167j//vux2+0kJCTw6aefUlNTwx133MG2bdtQSvHwww9z1VVXERkZSU1NDQBvvvkm77//Pi+++CI33HADoaGh7Nixgzlz5rBs2TLuvPNOrFYrYWFhvPDCC5xxxhnY7XZ++ctfsm7dOgICArj55puZMGECTz/9NO+++y4An3zyCX/5y1945513PPo76i3TBnp5bSOpAYXYI5OwBIX5ujhCCA95/vnniYuLo76+njPPPJPFixdz8803s3nzZkaMGEFZWRkAv/nNb4iOjmbPnj0AlJeXd3nsvLw8vvrqKywWC1VVVXz++ecEBgayfv167r//ft566y1Wr17N4cOH2blzJ4GBgZSVlREbG8ttt91GcXExAwcO5IUXXuAnP/mJV38PPWHaQM8uruWygEIC4qW5RQhPc6cm7S1PP/10S8332LFjrF69mrlz57b0x46LiwNg/fr1rFmzpmW/2Niux3JasmQJFosFgMrKSq6//noOHTqEUoqmpqaW495yyy0EBga2Od91113HK6+8wvLly/n66695+eWXPXTFnmPaNvSM41WMsBSj5IaoEH5j06ZNrF+/nq+//ppdu3YxdepUpkyZ0q1juHb3a9+POyIiouX9r371K84//3z27t3Le++912Wf7+XLl/PKK6/w+uuvs2TJkpbA709MGehaa46cKCTWUS49XITwI5WVlcTGxhIeHs6BAwfYsmULVquVzZs3k5ubC9DS5LJw4UKeeeaZln2bm1wGDx7M/v37cTgcp2zjrqysJDnZmE3zxRdfbFm+cOFC/vrXv7bcOG0+X1JSEklJSTz66KMsX77ccxftQaYM9LzyeuIajhsfpIeLEH5j0aJF2Gw20tLSWLlyJWeddRYDBw5k9erVXHnllaSnp7N06VIAHnzwQcrLy5k4cSLp6els3LgRgMcee4xLLrmEs88+m8TExE7Pde+993LfffcxderUNr1ebrrpJoYNG8bkyZNJT0/ntddea1l3zTXXMHToUNLS0rz0G+gdpbX2yYlnzJiht23b1qN9N36XQeHb97EscBP8dDMkpnu2cEKchvbv399vg6q/uP3225k6dSo33nhjn5yvo+9EKbVdaz2jo+37XyOQG4L3/YtlgZvQoTGo+NG+Lo4Q4jQwffp0IiIiePLJJ31dlE6ZMtDt1SU4UATcmwMBFl8XRwhxGti+fbuvi9AlU7ah6/pyKlS0hLkQQrgwZaBbrBXUBw7wdTGEEKJfMWWgBzdV0hQU7etiCCFEv2K6QLc22YlwVOMIlQmhhRDClekCvbDKSrSqJSC868d8hRDidGK6QD9eYSWaWoIj431dFCGED0VGRvq6CP2O6botFlZUMVvV0zRAAl0Ir/lwJZzY49ljDpkEFz7m2WP2Azabrd+M62K6GnpZSTEAkTEDfVwSIYQnrVy5ss3YLKtWreLRRx9lwYIFTJs2jUmTJvGf//zHrWPV1NR0ut/LL7/c8lj/ddddB0BhYSFXXHEF6enppKen89VXX3H48GEmTpzYst8TTzzBqlWrADjvvPO46667mDFjBk899RTvvfces2bNYurUqVxwwQUUFha2lGP58uVMmjSJyZMn89Zbb/H8889z1113tRz3b3/7G3fffXePf29taK198jN9+nTdE1VH92n98ACtd7/Ro/2FEB3LyMjw6fm/++47PXfu3JbPaWlp+ujRo7qyslJrrXVxcbEeNWqUdjgcWmutIyIiOj1WU1NTh/vt3btXjxkzRhcXF2uttS4tLdVaa3311VfrP/3pT1prrW02m66oqNC5ubl6woQJLcd8/PHH9cMPP6y11nrevHn61ltvbVlXVlbWUq6//e1v+p577tFaa33vvffqO++8s8121dXVeuTIkbqxsVFrrfXs2bP17t27O7yOjr4TYJvuJFf7x98J3RCFMRMJ0stFCL8ydepUioqKOH78OMXFxcTGxjJkyBDuvvtuNm/eTEBAAPn5+RQWFjJkyJBTHktrzf3333/Sfhs2bGDJkiUkJCQArWOdb9iwoWV8c4vFQnR0dJcTZjQPEgbGxBlLly6loKCAxsbGlrHbOxuzff78+bz//vukpaXR1NTEpEmTuvnb6pjpAp165y85THq5COFvlixZwptvvsmJEydYunQpr776KsXFxWzfvp2goCBSU1O7HLcc6PF+rgIDA3E4HC2fTzW2+h133ME999zDZZddxqZNm1qaZjpz00038dvf/pZx48Z5dChe07Whtwa61NCF8DdLly5lzZo1vPnmmyxZsoTKykoGDRpEUFAQGzdu5MiRI24dp7P95s+fzxtvvEFpaSnQOtb5ggULePbZZwGw2+1UVlYyePBgioqKKC0tpaGhgffff/+U52seW/2ll15qWd7ZmO2zZs3i2LFjvPbaa/zwhz9099fTJRMHutTQhfA3EyZMoLq6muTkZBITE7nmmmvYtm0bkyZN4uWXX2bcuHFuHaez/SZMmMADDzzAvHnzSE9P55577gHgqaeeYuPGjUyaNInp06eTkZFBUFAQDz30EDNnzmThwoWnPPeqVatYsmQJ06dPb2nOgc7HbAe4+uqrmTNnjltT57nLfOOhH/gv7HwNrn5ZBucSwoNkPPS+dckll3D33XezYMGCTrfp7njo5quhj7sYlr0qYS6EMKWKigrGjh1LWFjYKcO8J8x3U1QIIZz27NnT0pe8WUhICFu3bvVRiboWExNDZmamV44tgS6EaKG1Rinl62K4bdKkSezcudPXxfCKnjSHu9XkopRapJQ6qJTKUkqt7GB9iFLqX871W5VSqd0uiRDCp0JDQyktLe1RkAjP0lpTWlpKaGhot/brsoaulLIAzwALgTzgW6XUWq11hstmNwLlWuvRSqllwO+BpScfTQjRX6WkpJCXl0dxcbGviyIw/oFNSUnp1j7uNLnMBLK01jkASqk1wGLANdAXA6uc798E/lcppbT8Uy+EaQQFBbU84SjMyZ0ml2TgmMvnPOeyDrfRWtuASuCk4RCVUiuUUtuUUtukFiCEEJ7Vp90WtdartdYztNYzBg6U0RKFEMKT3An0fGCoy+cU57IOt1FKBQLRQKknCiiEEMI97rShfwuMUUqNwAjuZcCP2m2zFrge+Br4AbChq/bz7du3lyil3BuY4WQJQEkP9+1v5Fr6J7mW/kmuBYZ3tqLLQNda25RStwMfARbgea31PqXUIxjj8q4F/gH8UymVBZRhhH5Xx+1xm4tSaltnj76ajVxL/yTX0j/JtZyaWw8Waa0/AD5ot+whl/dWYIknCyaEEKJ7zDeWixBCiA6ZNdBX+7oAHiTX0j/JtfRPci2n4LPhc4UQQniWWWvoQggh2pFAF0IIP2G6QO9q5Mf+Til1WCm1Rym1Uym1zbksTin1iVLqkPO1X86vp5R6XilVpJTa67Ksw7Irw9PO72m3Umqa70p+sk6uZZVSKt/53exUSl3ksu4+57UcVEp93zelPplSaqhSaqNSKkMptU8pdadzuem+l1Ncixm/l1Cl1DdKqV3Oa/m1c/kI54i0Wc4RaoOdyz0zYq3W2jQ/GP3gs4GRQDCwCxjv63J18xoOAwntlv0BWOl8vxL4va/L2UnZ5wLTgL1dlR24CPgQUMBZwFZfl9+Na1kF/LyDbcc7/1sLAUY4/xu0+PoanGVLBKY530cBmc7ymu57OcW1mPF7UUCk830QsNX5+/43sMy5/DngVuf724DnnO+XAf/qyXnNVkNvGflRa90INI/8aHaLgeapwl8CLvdhWTqltd6M8eCYq87Kvhh4WRu2ADFKqcS+KWnXOrmWziwG1mitG7TWuUAWxn+LPqe1LtBaf+d8Xw3sxxgsz3TfyymupTP9+XvRWusa58cg548G5mOMSAsnfy/N39ebwALVg5lGzBbo7oz82N9p4GOl1Hal1ArnssFa6wLn+xPAYN8UrUc6K7tZv6vbnU0Rz7s0fZniWpx/pk/FqA2a+ntpdy1gwu9FKWVRSu0EioBPMP6CqNDGiLTQtrxujVjbFbMFuj84R2s9DbgQ+JlSaq7rSm38zWXKvqRmLrvTs8AoYApQADzp2+K4TykVCbwF3KW1rnJdZ7bvpYNrMeX3orW2a62nYAxoOBMY5+1zmi3Q3Rn5sV/TWuc7X4uAdzC+6MLmP3udr0W+K2G3dVZ2031XWutC5/+EDuBvtP753q+vRSkVhBGAr2qt33YuNuX30tG1mPV7aaa1rgA2ArMxmriah1xxLa9HRqw1W6C3jPzovDu8DGOkR1NQSkUopaKa3wPfA/bSOlolztf/+KaEPdJZ2dcCP3b2qjgLqHRpAuiX2rUlX4Hx3YBxLcucPRFGAGOAb/q6fB1xtrP+A9ivtf6jyyrTfS+dXYtJv5eBSqkY5/swjCk892ME+w+cm7X/Xpq/L7dGrO2Qr+8G9+Du8UUYd7+zgQd8XZ5uln0kxl35XcC+5vJjtJV9ChwC1gNxvi5rJ+V/HeNP3iaM9r8bOys7xl3+Z5zf0x5ghq/L78a1/NNZ1t3O/8ESXbZ/wHktB4ELfV1+l3Kdg9GcshvY6fy5yIzfyymuxYzfy2Rgh7PMe4GHnMtHYvyjkwW8AYQ4l4c6P2c514/syXnl0X8hhPATZmtyEUII0QkJdCGE8BMS6EII4Sck0IUQwk9IoAshhJ+QQBdCCD8hgS6EEH7i/wOQbZn3uRZqoAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IwtAtB0TPxmF",
        "outputId": "d97839fe-ea95-498a-b9f2-243b7cb3b8f0"
      },
      "source": [
        "model.evaluate(scaled_X_test,y_test,verbose=0)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4770860970020294, 0.9333333373069763]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOpEwQhmP3r0"
      },
      "source": [
        "## Ready Model for Deployment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JO15ilmFP0zj"
      },
      "source": [
        "epochs = len(metrics)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTKkT4SdP6sv"
      },
      "source": [
        "# all the data\n",
        "scaled_X = scaler.fit_transform(X)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHfWiab6RCRY"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(units=4,activation='relu'))\n",
        "\n",
        "# Last layer for multi-class classification of 3 species\n",
        "model.add(Dense(units=3,activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXIjN3PgRLNZ",
        "outputId": "d110f4fd-dc49-4eee-8564-c241a15db52a"
      },
      "source": [
        "model.fit(scaled_X,y,epochs=epochs)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0739 - accuracy: 0.3333\n",
            "Epoch 2/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0695 - accuracy: 0.3333\n",
            "Epoch 3/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0651 - accuracy: 0.3333\n",
            "Epoch 4/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0607 - accuracy: 0.3333\n",
            "Epoch 5/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0560 - accuracy: 0.3333\n",
            "Epoch 6/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0515 - accuracy: 0.3333\n",
            "Epoch 7/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0468 - accuracy: 0.3333\n",
            "Epoch 8/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0421 - accuracy: 0.3333\n",
            "Epoch 9/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0374 - accuracy: 0.3333\n",
            "Epoch 10/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0327 - accuracy: 0.3333\n",
            "Epoch 11/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0279 - accuracy: 0.3333\n",
            "Epoch 12/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0231 - accuracy: 0.3333\n",
            "Epoch 13/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0183 - accuracy: 0.3333\n",
            "Epoch 14/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0134 - accuracy: 0.3333\n",
            "Epoch 15/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0085 - accuracy: 0.3333\n",
            "Epoch 16/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0037 - accuracy: 0.3333\n",
            "Epoch 17/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9988 - accuracy: 0.3333\n",
            "Epoch 18/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9939 - accuracy: 0.3333\n",
            "Epoch 19/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9890 - accuracy: 0.3333\n",
            "Epoch 20/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9841 - accuracy: 0.3333\n",
            "Epoch 21/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9792 - accuracy: 0.3333\n",
            "Epoch 22/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9743 - accuracy: 0.3333\n",
            "Epoch 23/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9694 - accuracy: 0.3333\n",
            "Epoch 24/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9645 - accuracy: 0.3333\n",
            "Epoch 25/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9598 - accuracy: 0.3333\n",
            "Epoch 26/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9551 - accuracy: 0.3333\n",
            "Epoch 27/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9506 - accuracy: 0.3533\n",
            "Epoch 28/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9460 - accuracy: 0.3667\n",
            "Epoch 29/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9414 - accuracy: 0.3867\n",
            "Epoch 30/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9370 - accuracy: 0.3867\n",
            "Epoch 31/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9325 - accuracy: 0.3933\n",
            "Epoch 32/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9281 - accuracy: 0.4000\n",
            "Epoch 33/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9238 - accuracy: 0.4133\n",
            "Epoch 34/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9195 - accuracy: 0.4667\n",
            "Epoch 35/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9151 - accuracy: 0.5067\n",
            "Epoch 36/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9108 - accuracy: 0.5200\n",
            "Epoch 37/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9066 - accuracy: 0.5533\n",
            "Epoch 38/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9024 - accuracy: 0.5667\n",
            "Epoch 39/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8981 - accuracy: 0.5667\n",
            "Epoch 40/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8940 - accuracy: 0.6067\n",
            "Epoch 41/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.8898 - accuracy: 0.6200\n",
            "Epoch 42/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8855 - accuracy: 0.6333\n",
            "Epoch 43/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8813 - accuracy: 0.6400\n",
            "Epoch 44/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8773 - accuracy: 0.6400\n",
            "Epoch 45/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8731 - accuracy: 0.6400\n",
            "Epoch 46/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8690 - accuracy: 0.6467\n",
            "Epoch 47/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8650 - accuracy: 0.6467\n",
            "Epoch 48/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8609 - accuracy: 0.6467\n",
            "Epoch 49/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8570 - accuracy: 0.6533\n",
            "Epoch 50/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8530 - accuracy: 0.6533\n",
            "Epoch 51/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8490 - accuracy: 0.6667\n",
            "Epoch 52/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8450 - accuracy: 0.6667\n",
            "Epoch 53/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8412 - accuracy: 0.6667\n",
            "Epoch 54/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.8373 - accuracy: 0.6667\n",
            "Epoch 55/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8333 - accuracy: 0.6667\n",
            "Epoch 56/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8294 - accuracy: 0.6733\n",
            "Epoch 57/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8255 - accuracy: 0.6800\n",
            "Epoch 58/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8216 - accuracy: 0.6733\n",
            "Epoch 59/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8177 - accuracy: 0.6800\n",
            "Epoch 60/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8139 - accuracy: 0.6800\n",
            "Epoch 61/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8099 - accuracy: 0.6800\n",
            "Epoch 62/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8061 - accuracy: 0.6800\n",
            "Epoch 63/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8022 - accuracy: 0.6800\n",
            "Epoch 64/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7983 - accuracy: 0.6800\n",
            "Epoch 65/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7943 - accuracy: 0.6800\n",
            "Epoch 66/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7906 - accuracy: 0.6800\n",
            "Epoch 67/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7866 - accuracy: 0.6800\n",
            "Epoch 68/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7828 - accuracy: 0.6800\n",
            "Epoch 69/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7789 - accuracy: 0.6867\n",
            "Epoch 70/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7749 - accuracy: 0.6867\n",
            "Epoch 71/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7712 - accuracy: 0.6933\n",
            "Epoch 72/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7674 - accuracy: 0.6933\n",
            "Epoch 73/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7634 - accuracy: 0.6933\n",
            "Epoch 74/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7596 - accuracy: 0.6933\n",
            "Epoch 75/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7556 - accuracy: 0.6933\n",
            "Epoch 76/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7518 - accuracy: 0.6933\n",
            "Epoch 77/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7479 - accuracy: 0.6933\n",
            "Epoch 78/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7441 - accuracy: 0.6933\n",
            "Epoch 79/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7402 - accuracy: 0.6933\n",
            "Epoch 80/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7363 - accuracy: 0.6933\n",
            "Epoch 81/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7326 - accuracy: 0.7000\n",
            "Epoch 82/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7286 - accuracy: 0.7067\n",
            "Epoch 83/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7248 - accuracy: 0.7067\n",
            "Epoch 84/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7210 - accuracy: 0.7067\n",
            "Epoch 85/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7171 - accuracy: 0.7067\n",
            "Epoch 86/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.7133 - accuracy: 0.7133\n",
            "Epoch 87/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7095 - accuracy: 0.7133\n",
            "Epoch 88/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7056 - accuracy: 0.7133\n",
            "Epoch 89/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7019 - accuracy: 0.7133\n",
            "Epoch 90/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6980 - accuracy: 0.7133\n",
            "Epoch 91/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6941 - accuracy: 0.7133\n",
            "Epoch 92/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6904 - accuracy: 0.7133\n",
            "Epoch 93/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6865 - accuracy: 0.7133\n",
            "Epoch 94/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6826 - accuracy: 0.7133\n",
            "Epoch 95/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6787 - accuracy: 0.7133\n",
            "Epoch 96/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6751 - accuracy: 0.7200\n",
            "Epoch 97/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6712 - accuracy: 0.7267\n",
            "Epoch 98/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6673 - accuracy: 0.7267\n",
            "Epoch 99/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6636 - accuracy: 0.7267\n",
            "Epoch 100/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6601 - accuracy: 0.7333\n",
            "Epoch 101/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6561 - accuracy: 0.7333\n",
            "Epoch 102/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6523 - accuracy: 0.7333\n",
            "Epoch 103/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6487 - accuracy: 0.7333\n",
            "Epoch 104/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6449 - accuracy: 0.7333\n",
            "Epoch 105/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6413 - accuracy: 0.7333\n",
            "Epoch 106/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6375 - accuracy: 0.7333\n",
            "Epoch 107/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6340 - accuracy: 0.7333\n",
            "Epoch 108/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6304 - accuracy: 0.7333\n",
            "Epoch 109/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6268 - accuracy: 0.7333\n",
            "Epoch 110/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6232 - accuracy: 0.7333\n",
            "Epoch 111/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6196 - accuracy: 0.7333\n",
            "Epoch 112/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6159 - accuracy: 0.7333\n",
            "Epoch 113/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6124 - accuracy: 0.7467\n",
            "Epoch 114/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6090 - accuracy: 0.7467\n",
            "Epoch 115/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6054 - accuracy: 0.7533\n",
            "Epoch 116/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6021 - accuracy: 0.7600\n",
            "Epoch 117/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5985 - accuracy: 0.7600\n",
            "Epoch 118/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5951 - accuracy: 0.7600\n",
            "Epoch 119/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5917 - accuracy: 0.7600\n",
            "Epoch 120/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5884 - accuracy: 0.7600\n",
            "Epoch 121/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5850 - accuracy: 0.7667\n",
            "Epoch 122/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5817 - accuracy: 0.7733\n",
            "Epoch 123/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5784 - accuracy: 0.7733\n",
            "Epoch 124/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5753 - accuracy: 0.7800\n",
            "Epoch 125/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5720 - accuracy: 0.7867\n",
            "Epoch 126/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5689 - accuracy: 0.7933\n",
            "Epoch 127/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5658 - accuracy: 0.8000\n",
            "Epoch 128/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5627 - accuracy: 0.8067\n",
            "Epoch 129/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5597 - accuracy: 0.8000\n",
            "Epoch 130/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5565 - accuracy: 0.8000\n",
            "Epoch 131/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5537 - accuracy: 0.8000\n",
            "Epoch 132/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5508 - accuracy: 0.8000\n",
            "Epoch 133/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5476 - accuracy: 0.8000\n",
            "Epoch 134/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5447 - accuracy: 0.8133\n",
            "Epoch 135/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5418 - accuracy: 0.8133\n",
            "Epoch 136/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5389 - accuracy: 0.8133\n",
            "Epoch 137/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5361 - accuracy: 0.8133\n",
            "Epoch 138/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5333 - accuracy: 0.8267\n",
            "Epoch 139/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5306 - accuracy: 0.8267\n",
            "Epoch 140/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5278 - accuracy: 0.8267\n",
            "Epoch 141/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5251 - accuracy: 0.8267\n",
            "Epoch 142/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5224 - accuracy: 0.8267\n",
            "Epoch 143/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5200 - accuracy: 0.8267\n",
            "Epoch 144/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5174 - accuracy: 0.8333\n",
            "Epoch 145/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5145 - accuracy: 0.8267\n",
            "Epoch 146/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5121 - accuracy: 0.8333\n",
            "Epoch 147/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5094 - accuracy: 0.8467\n",
            "Epoch 148/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5070 - accuracy: 0.8533\n",
            "Epoch 149/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.8533\n",
            "Epoch 150/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5021 - accuracy: 0.8533\n",
            "Epoch 151/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4997 - accuracy: 0.8533\n",
            "Epoch 152/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4974 - accuracy: 0.8533\n",
            "Epoch 153/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4951 - accuracy: 0.8467\n",
            "Epoch 154/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4928 - accuracy: 0.8533\n",
            "Epoch 155/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4904 - accuracy: 0.8533\n",
            "Epoch 156/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4881 - accuracy: 0.8533\n",
            "Epoch 157/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4859 - accuracy: 0.8533\n",
            "Epoch 158/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4838 - accuracy: 0.8533\n",
            "Epoch 159/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4814 - accuracy: 0.8533\n",
            "Epoch 160/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4792 - accuracy: 0.8533\n",
            "Epoch 161/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4772 - accuracy: 0.8600\n",
            "Epoch 162/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4750 - accuracy: 0.8600\n",
            "Epoch 163/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4729 - accuracy: 0.8733\n",
            "Epoch 164/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4707 - accuracy: 0.8800\n",
            "Epoch 165/300\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4687 - accuracy: 0.8800\n",
            "Epoch 166/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4666 - accuracy: 0.8800\n",
            "Epoch 167/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4646 - accuracy: 0.8800\n",
            "Epoch 168/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4626 - accuracy: 0.8800\n",
            "Epoch 169/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4607 - accuracy: 0.8800\n",
            "Epoch 170/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4586 - accuracy: 0.8867\n",
            "Epoch 171/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4570 - accuracy: 0.8800\n",
            "Epoch 172/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4548 - accuracy: 0.8800\n",
            "Epoch 173/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4529 - accuracy: 0.8800\n",
            "Epoch 174/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4511 - accuracy: 0.8800\n",
            "Epoch 175/300\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.4492 - accuracy: 0.8800\n",
            "Epoch 176/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4472 - accuracy: 0.8800\n",
            "Epoch 177/300\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.4455 - accuracy: 0.8867\n",
            "Epoch 178/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4437 - accuracy: 0.8867\n",
            "Epoch 179/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4417 - accuracy: 0.8867\n",
            "Epoch 180/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4401 - accuracy: 0.8933\n",
            "Epoch 181/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4382 - accuracy: 0.9000\n",
            "Epoch 182/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.4366 - accuracy: 0.9000\n",
            "Epoch 183/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4347 - accuracy: 0.9000\n",
            "Epoch 184/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4330 - accuracy: 0.9000\n",
            "Epoch 185/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4312 - accuracy: 0.9000\n",
            "Epoch 186/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4296 - accuracy: 0.9000\n",
            "Epoch 187/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4280 - accuracy: 0.9000\n",
            "Epoch 188/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4263 - accuracy: 0.9000\n",
            "Epoch 189/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4248 - accuracy: 0.9067\n",
            "Epoch 190/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4229 - accuracy: 0.9200\n",
            "Epoch 191/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4213 - accuracy: 0.9200\n",
            "Epoch 192/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4198 - accuracy: 0.9200\n",
            "Epoch 193/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.4181 - accuracy: 0.9200\n",
            "Epoch 194/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4165 - accuracy: 0.9200\n",
            "Epoch 195/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4149 - accuracy: 0.9200\n",
            "Epoch 196/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4133 - accuracy: 0.9200\n",
            "Epoch 197/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4118 - accuracy: 0.9200\n",
            "Epoch 198/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.9200\n",
            "Epoch 199/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4087 - accuracy: 0.9200\n",
            "Epoch 200/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4073 - accuracy: 0.9267\n",
            "Epoch 201/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4057 - accuracy: 0.9267\n",
            "Epoch 202/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4042 - accuracy: 0.9267\n",
            "Epoch 203/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4026 - accuracy: 0.9267\n",
            "Epoch 204/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4013 - accuracy: 0.9200\n",
            "Epoch 205/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3998 - accuracy: 0.9200\n",
            "Epoch 206/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3983 - accuracy: 0.9200\n",
            "Epoch 207/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.3970 - accuracy: 0.9267\n",
            "Epoch 208/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3953 - accuracy: 0.9333\n",
            "Epoch 209/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.3939 - accuracy: 0.9333\n",
            "Epoch 210/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.3925 - accuracy: 0.9333\n",
            "Epoch 211/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3910 - accuracy: 0.9333\n",
            "Epoch 212/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3896 - accuracy: 0.9333\n",
            "Epoch 213/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3882 - accuracy: 0.9333\n",
            "Epoch 214/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3867 - accuracy: 0.9333\n",
            "Epoch 215/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3854 - accuracy: 0.9333\n",
            "Epoch 216/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3843 - accuracy: 0.9333\n",
            "Epoch 217/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3826 - accuracy: 0.9333\n",
            "Epoch 218/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3812 - accuracy: 0.9333\n",
            "Epoch 219/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3798 - accuracy: 0.9333\n",
            "Epoch 220/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3788 - accuracy: 0.9333\n",
            "Epoch 221/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3772 - accuracy: 0.9333\n",
            "Epoch 222/300\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.3759 - accuracy: 0.9333\n",
            "Epoch 223/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3746 - accuracy: 0.9333\n",
            "Epoch 224/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3732 - accuracy: 0.9333\n",
            "Epoch 225/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3719 - accuracy: 0.9333\n",
            "Epoch 226/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3707 - accuracy: 0.9333\n",
            "Epoch 227/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3693 - accuracy: 0.9333\n",
            "Epoch 228/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3680 - accuracy: 0.9333\n",
            "Epoch 229/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3667 - accuracy: 0.9333\n",
            "Epoch 230/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3658 - accuracy: 0.9333\n",
            "Epoch 231/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3641 - accuracy: 0.9333\n",
            "Epoch 232/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3628 - accuracy: 0.9333\n",
            "Epoch 233/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3616 - accuracy: 0.9400\n",
            "Epoch 234/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3603 - accuracy: 0.9400\n",
            "Epoch 235/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3590 - accuracy: 0.9400\n",
            "Epoch 236/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3577 - accuracy: 0.9400\n",
            "Epoch 237/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3565 - accuracy: 0.9400\n",
            "Epoch 238/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3552 - accuracy: 0.9400\n",
            "Epoch 239/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3540 - accuracy: 0.9400\n",
            "Epoch 240/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3529 - accuracy: 0.9333\n",
            "Epoch 241/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3515 - accuracy: 0.9333\n",
            "Epoch 242/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3503 - accuracy: 0.9400\n",
            "Epoch 243/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3490 - accuracy: 0.9400\n",
            "Epoch 244/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3479 - accuracy: 0.9400\n",
            "Epoch 245/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3466 - accuracy: 0.9333\n",
            "Epoch 246/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3455 - accuracy: 0.9400\n",
            "Epoch 247/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3442 - accuracy: 0.9400\n",
            "Epoch 248/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3430 - accuracy: 0.9333\n",
            "Epoch 249/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3419 - accuracy: 0.9333\n",
            "Epoch 250/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3406 - accuracy: 0.9400\n",
            "Epoch 251/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3394 - accuracy: 0.9400\n",
            "Epoch 252/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3382 - accuracy: 0.9400\n",
            "Epoch 253/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3372 - accuracy: 0.9400\n",
            "Epoch 254/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3358 - accuracy: 0.9400\n",
            "Epoch 255/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3352 - accuracy: 0.9400\n",
            "Epoch 256/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3337 - accuracy: 0.9400\n",
            "Epoch 257/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3324 - accuracy: 0.9400\n",
            "Epoch 258/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3312 - accuracy: 0.9400\n",
            "Epoch 259/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3305 - accuracy: 0.9467\n",
            "Epoch 260/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3290 - accuracy: 0.9400\n",
            "Epoch 261/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3277 - accuracy: 0.9400\n",
            "Epoch 262/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3266 - accuracy: 0.9400\n",
            "Epoch 263/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3256 - accuracy: 0.9400\n",
            "Epoch 264/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3246 - accuracy: 0.9400\n",
            "Epoch 265/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3233 - accuracy: 0.9400\n",
            "Epoch 266/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3223 - accuracy: 0.9400\n",
            "Epoch 267/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3210 - accuracy: 0.9400\n",
            "Epoch 268/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3201 - accuracy: 0.9533\n",
            "Epoch 269/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3189 - accuracy: 0.9533\n",
            "Epoch 270/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3178 - accuracy: 0.9533\n",
            "Epoch 271/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3167 - accuracy: 0.9467\n",
            "Epoch 272/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3156 - accuracy: 0.9533\n",
            "Epoch 273/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3145 - accuracy: 0.9467\n",
            "Epoch 274/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3135 - accuracy: 0.9533\n",
            "Epoch 275/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3123 - accuracy: 0.9600\n",
            "Epoch 276/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3114 - accuracy: 0.9600\n",
            "Epoch 277/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3102 - accuracy: 0.9667\n",
            "Epoch 278/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3092 - accuracy: 0.9600\n",
            "Epoch 279/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3081 - accuracy: 0.9533\n",
            "Epoch 280/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3071 - accuracy: 0.9533\n",
            "Epoch 281/300\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.3061 - accuracy: 0.9533\n",
            "Epoch 282/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3050 - accuracy: 0.9533\n",
            "Epoch 283/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3040 - accuracy: 0.9533\n",
            "Epoch 284/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3030 - accuracy: 0.9533\n",
            "Epoch 285/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3019 - accuracy: 0.9533\n",
            "Epoch 286/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3009 - accuracy: 0.9667\n",
            "Epoch 287/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2999 - accuracy: 0.9667\n",
            "Epoch 288/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2988 - accuracy: 0.9667\n",
            "Epoch 289/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2978 - accuracy: 0.9667\n",
            "Epoch 290/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2968 - accuracy: 0.9667\n",
            "Epoch 291/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2958 - accuracy: 0.9667\n",
            "Epoch 292/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2949 - accuracy: 0.9600\n",
            "Epoch 293/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2940 - accuracy: 0.9667\n",
            "Epoch 294/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2928 - accuracy: 0.9667\n",
            "Epoch 295/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2923 - accuracy: 0.9667\n",
            "Epoch 296/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2908 - accuracy: 0.9600\n",
            "Epoch 297/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2900 - accuracy: 0.9600\n",
            "Epoch 298/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.2890 - accuracy: 0.9600\n",
            "Epoch 299/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2880 - accuracy: 0.9600\n",
            "Epoch 300/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2870 - accuracy: 0.9667\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2d8a25fc90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tTdoUlbRN1R",
        "outputId": "5f49ffb6-b495-4313-f7ce-83415a365167"
      },
      "source": [
        "model.evaluate(scaled_X_test,y_test,verbose=0)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3098078966140747, 0.9666666388511658]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0ValsogRU7W"
      },
      "source": [
        "model.save(\"final_iris_model.h5\")"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x47qmPeaRiET"
      },
      "source": [
        "### Saving Scaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Z68QXKNRd6d"
      },
      "source": [
        "import joblib"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LOQcJG3Rn2k",
        "outputId": "ab22ec65-2901-455a-ed1f-ca6bd6607447"
      },
      "source": [
        "joblib.dump(scaler,'iris_scaler.pkl')"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['iris_scaler.pkl']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dchX56tqSAWk"
      },
      "source": [
        "## Predicting a Single New Flower"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3Wcmn4dRpw0"
      },
      "source": [
        "from tensorflow.keras.models import load_model"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NBH1VlUSC64"
      },
      "source": [
        "flower_model = load_model(\"final_iris_model.h5\")"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtXuO_L8SHGk"
      },
      "source": [
        "flower_scaler = joblib.load(\"iris_scaler.pkl\")"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "AU17zTU_SIOm",
        "outputId": "94fc8f74-bd09-47d0-e0a8-6bd8d4525e56"
      },
      "source": [
        "iris.head(1)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal_length</th>\n",
              "      <th>sepal_width</th>\n",
              "      <th>petal_length</th>\n",
              "      <th>petal_width</th>\n",
              "      <th>species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sepal_length  sepal_width  petal_length  petal_width species\n",
              "0           5.1          3.5           1.4          0.2  setosa"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjTqfpm4SN73"
      },
      "source": [
        "flower_example = {'sepal_length':5.1,\n",
        "                 'sepal_width':3.5,\n",
        "                 'petal_length':1.4,\n",
        "                 'petal_width':0.2}"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcELJgWXSPyx",
        "outputId": "81f5ccc4-4ba5-4bdc-ffe9-f42bfe767905"
      },
      "source": [
        "flower_example.keys()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['sepal_length', 'sepal_width', 'petal_length', 'petal_width'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJWFFsibSREb",
        "outputId": "848c2a58-54aa-4bdd-e607-3eded4ec9598"
      },
      "source": [
        "encoder.classes_"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nkie-df_SUkQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}