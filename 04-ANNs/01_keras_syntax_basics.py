# -*- coding: utf-8 -*-
"""01-Keras-Syntax-Basics.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dG5e3DU4rcrMUgigrzpopohnFfCgBuSg

# Keras Syntax Basics

With TensorFlow 2.0 , Keras is now the main API choice. Let's work through a simple regression project to understand the basics of the Keras syntax and adding layers.

## The Data

To learn the basic syntax of Keras, we will use a very simple fake data set, in the subsequent lectures we will focus on real datasets, along with feature engineering! For now, let's focus on the syntax of TensorFlow 2.0.

Let's pretend this data are measurements of some rare gem stones, with 2 measurement features and a sale price. Our final goal would be to try to predict the sale price of a new gem stone we just mined from the ground, in order to try to set a fair price in the market.
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

df = pd.read_csv('fake_reg.csv')

df.head()

"""### Explore the data

Let's take a quick look, we should see strong correlation between the features and the "price" of this made up product.
"""

# pairplot do DF
sns.pairplot(df);

"""### Test/Train Split"""

# importando sklearn
from sklearn.model_selection import train_test_split

# Convertendo de Pandas para Numpy devido ao Keras

# entradas
X = df[['feature1', 'feature2']].values # devido ao TensorFlow, passamos como 'NP array', em vez de 'Pandas DF'

# saída da mesma forma, como NP array
y = df['price'].values

# separando nossas variáveis de treino e teste
# pelo HELP da função 'train_test_split' podemos ver a sequência de retorno
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

X_train.shape

X_test.shape

"""## Normalizing/Scaling the Data

We scale the feature data.

[Why we don't need to scale the label](https://stats.stackexchange.com/questions/111467/is-it-necessary-to-scale-the-target-value-in-addition-to-scaling-features-for-re)
"""

from sklearn.preprocessing import MinMaxScaler

# MinMaxScaler vai transformar os dados baseado no Desvio Padrão dos dados
# não precisa normalizar o label 'y', apenas as features 'X'
help(MinMaxScaler)

# instaciando o 'scaler'
scaler = MinMaxScaler()

# treinando o 'scaler' no dados de treino
# .fit() calcula o STD, MIN e MAX para normalizar
# treinamos APENAS os dados de treino para garantirmos que não estamos visualizando os 
# dados de treino previamente
scaler.fit(X_train)

# transformando nossos dados
X_train = scaler.transform(X_train)

# transformando
X_test = scaler.transform(X_test)

# dado normalizado
X_train.max()

# dado normalizado
X_train.min()

"""# TensorFlow 2.0 Syntax


## Import Options

There are several ways you can import Keras from Tensorflow (this is hugely a personal style choice, please use any import methods you prefer). We will use the method shown in the **official TF documentation**.
"""

import tensorflow as tf

from tensorflow.keras.models import Sequential

# entendendo a função
help(Sequential)

